"""
ç´¢å¼•ç®¡ç†å™¨æ¨¡å—

æä¾›å‘é‡ç´¢å¼•çš„ç»Ÿä¸€ç®¡ç†æŽ¥å£ï¼ŒåŒ…æ‹¬ï¼š
- ç´¢å¼•çš„åˆ›å»ºã€åŠ è½½ã€ä¿å­˜ã€åˆ é™¤
- ç´¢å¼•å…ƒæ•°æ®ç®¡ç†
- ç´¢å¼•åˆ—è¡¨å’Œç»Ÿè®¡

ç´¢å¼•ç»“æž„ï¼š
data/indexes/
  â”œâ”€â”€ index_name/
  â”‚   â”œâ”€â”€ index.faiss        # FAISS ç´¢å¼•æ–‡ä»¶
  â”‚   â”œâ”€â”€ index.pkl          # FAISS æ–‡æ¡£å­˜å‚¨
  â”‚   â””â”€â”€ metadata.json      # ç´¢å¼•å…ƒæ•°æ®
"""

import json
from pathlib import Path
from typing import List, Optional, Dict, Any
from datetime import datetime
from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings
from langchain_core.vectorstores import VectorStore

from config import settings, get_logger
from rag.vector_stores import (
    create_vector_store,
    load_vector_store,
    save_vector_store,
    add_documents_to_vector_store,
    delete_vector_store,
    get_vector_store_stats,
)

logger = get_logger(__name__)


class IndexManager:
    """
    ç´¢å¼•ç®¡ç†å™¨
    
    ç®¡ç†æ‰€æœ‰å‘é‡ç´¢å¼•çš„ç”Ÿå‘½å‘¨æœŸï¼ŒåŒ…æ‹¬åˆ›å»ºã€åŠ è½½ã€æ›´æ–°ã€åˆ é™¤ç­‰æ“ä½œã€‚
    
    Example:
        >>> from rag import IndexManager, get_embeddings
        >>> 
        >>> # åˆ›å»ºç®¡ç†å™¨
        >>> manager = IndexManager()
        >>> embeddings = get_embeddings()
        >>> 
        >>> # åˆ›å»ºç´¢å¼•
        >>> manager.create_index(
        ...     name="my_docs",
        ...     documents=chunks,
        ...     embeddings=embeddings,
        ...     description="æˆ‘çš„æ–‡æ¡£ç´¢å¼•"
        ... )
        >>> 
        >>> # åˆ—å‡ºæ‰€æœ‰ç´¢å¼•
        >>> indexes = manager.list_indexes()
        >>> 
        >>> # åŠ è½½ç´¢å¼•
        >>> vector_store = manager.load_index("my_docs", embeddings)
        >>> 
        >>> # åˆ é™¤ç´¢å¼•
        >>> manager.delete_index("my_docs")
    """
    
    def __init__(self, base_path: Optional[str] = None):
        """
        åˆå§‹åŒ–ç´¢å¼•ç®¡ç†å™¨
        
        Args:
            base_path: ç´¢å¼•å­˜å‚¨çš„åŸºç¡€è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„
        """
        self.base_path = Path(base_path or settings.vector_store_path)
        self.base_path.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ðŸ“ ç´¢å¼•ç®¡ç†å™¨åˆå§‹åŒ–: {self.base_path}")
    
    def _get_index_path(self, name: str) -> Path:
        """èŽ·å–ç´¢å¼•çš„å®Œæ•´è·¯å¾„"""
        return self.base_path / name
    
    def _get_metadata_path(self, name: str) -> Path:
        """èŽ·å–ç´¢å¼•å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„"""
        return self._get_index_path(name) / "metadata.json"
    
    def _save_metadata(
        self,
        name: str,
        metadata: Dict[str, Any],
    ) -> None:
        """ä¿å­˜ç´¢å¼•å…ƒæ•°æ®"""
        metadata_path = self._get_metadata_path(name)
        metadata_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        logger.debug(f"ðŸ’¾ ä¿å­˜å…ƒæ•°æ®: {metadata_path}")
    
    def _load_metadata(self, name: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½ç´¢å¼•å…ƒæ•°æ®"""
        metadata_path = self._get_metadata_path(name)
        
        if not metadata_path.exists():
            return None
        
        try:
            with open(metadata_path, "r", encoding="utf-8") as f:
                metadata = json.load(f)
            return metadata
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å…ƒæ•°æ®å¤±è´¥: {e}")
            return None
    
    def create_index(
        self,
        name: str,
        documents: List[Document],
        embeddings: Embeddings,
        description: str = "",
        store_type: Optional[str] = None,
        overwrite: bool = False,
        **kwargs,
    ) -> VectorStore:
        """
        åˆ›å»ºæ–°ç´¢å¼•
        
        Args:
            name: ç´¢å¼•åç§°
            documents: æ–‡æ¡£åˆ—è¡¨
            embeddings: Embedding æ¨¡åž‹
            description: ç´¢å¼•æè¿°
            store_type: å‘é‡åº“ç±»åž‹
            overwrite: æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„ç´¢å¼•
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            åˆ›å»ºçš„ VectorStore å®žä¾‹
            
        Raises:
            ValueError: å¦‚æžœç´¢å¼•å·²å­˜åœ¨ä¸” overwrite=False
            
        Example:
            >>> manager.create_index(
            ...     name="my_docs",
            ...     documents=chunks,
            ...     embeddings=embeddings,
            ...     description="æˆ‘çš„æ–‡æ¡£é›†åˆ"
            ... )
        """
        index_path = self._get_index_path(name)
        
        # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å·²å­˜åœ¨
        if index_path.exists() and not overwrite:
            raise ValueError(
                f"ç´¢å¼•å·²å­˜åœ¨: {name}ã€‚ä½¿ç”¨ overwrite=True æ¥è¦†ç›–ã€‚"
            )
        
        logger.info(f"ðŸ”¨ åˆ›å»ºç´¢å¼•: {name}")
        logger.info(f"   æ–‡æ¡£æ•°é‡: {len(documents)}")
        logger.info(f"   æè¿°: {description}")
        
        try:
            # åˆ›å»ºå‘é‡åº“
            vector_store = create_vector_store(
                documents=documents,
                embeddings=embeddings,
                store_type=store_type,
                **kwargs,
            )
            
            # ä¿å­˜å‘é‡åº“
            save_vector_store(vector_store, str(index_path), embeddings)
            
            # ä¿å­˜å…ƒæ•°æ®
            metadata = {
                "name": name,
                "description": description,
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat(),
                "num_documents": len(documents),
                "store_type": store_type or settings.vector_store_type,
                "embedding_model": settings.embedding_model,
            }
            self._save_metadata(name, metadata)
            
            logger.info(f"âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸ: {name}")
            return vector_store
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
            # æ¸…ç†å¤±è´¥çš„ç´¢å¼•
            if index_path.exists():
                delete_vector_store(str(index_path))
            raise
    
    def load_index(
        self,
        name: str,
        embeddings: Embeddings,
        **kwargs,
    ) -> VectorStore:
        """
        åŠ è½½ç´¢å¼•
        
        Args:
            name: ç´¢å¼•åç§°
            embeddings: Embedding æ¨¡åž‹
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            VectorStore å®žä¾‹
            
        Raises:
            FileNotFoundError: å¦‚æžœç´¢å¼•ä¸å­˜åœ¨
            
        Example:
            >>> vector_store = manager.load_index("my_docs", embeddings)
        """
        index_path = self._get_index_path(name)
        
        if not index_path.exists():
            raise FileNotFoundError(f"ç´¢å¼•ä¸å­˜åœ¨: {name}")
        
        logger.info(f"ðŸ“‚ åŠ è½½ç´¢å¼•: {name}")
        
        try:
            # åŠ è½½å…ƒæ•°æ®
            metadata = self._load_metadata(name)
            if metadata:
                logger.info(f"   æè¿°: {metadata.get('description', 'N/A')}")
                logger.info(f"   æ–‡æ¡£æ•°: {metadata.get('num_documents', 'N/A')}")
            
            # åŠ è½½å‘é‡åº“
            vector_store = load_vector_store(
                load_path=str(index_path),
                embeddings=embeddings,
                **kwargs,
            )
            
            logger.info(f"âœ… ç´¢å¼•åŠ è½½æˆåŠŸ: {name}")
            return vector_store
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ç´¢å¼•å¤±è´¥: {e}")
            raise
    
    def update_index(
        self,
        name: str,
        documents: List[Document],
        embeddings: Embeddings,
        **kwargs,
    ) -> VectorStore:
        """
        æ›´æ–°ç´¢å¼•ï¼ˆæ·»åŠ æ–°æ–‡æ¡£ï¼‰
        
        Args:
            name: ç´¢å¼•åç§°
            documents: è¦æ·»åŠ çš„æ–‡æ¡£åˆ—è¡¨
            embeddings: Embedding æ¨¡åž‹
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            æ›´æ–°åŽçš„ VectorStore å®žä¾‹
            
        Example:
            >>> # åŠ è½½æ–°æ–‡æ¡£
            >>> new_docs = load_document("new_doc.pdf")
            >>> chunks = split_documents(new_docs)
            >>> 
            >>> # æ›´æ–°ç´¢å¼•
            >>> manager.update_index("my_docs", chunks, embeddings)
        """
        logger.info(f"ðŸ”„ æ›´æ–°ç´¢å¼•: {name}")
        logger.info(f"   æ–°å¢žæ–‡æ¡£: {len(documents)}")
        
        try:
            # åŠ è½½çŽ°æœ‰ç´¢å¼•
            vector_store = self.load_index(name, embeddings, **kwargs)
            
            # æ·»åŠ æ–°æ–‡æ¡£
            add_documents_to_vector_store(vector_store, documents)
            
            # ä¿å­˜æ›´æ–°åŽçš„å‘é‡åº“
            index_path = self._get_index_path(name)
            save_vector_store(vector_store, str(index_path), embeddings)
            
            # æ›´æ–°å…ƒæ•°æ®
            metadata = self._load_metadata(name) or {}
            metadata["updated_at"] = datetime.now().isoformat()
            metadata["num_documents"] = metadata.get("num_documents", 0) + len(documents)
            self._save_metadata(name, metadata)
            
            logger.info(f"âœ… ç´¢å¼•æ›´æ–°æˆåŠŸ: {name}")
            return vector_store
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç´¢å¼•å¤±è´¥: {e}")
            raise
    
    def delete_index(self, name: str) -> None:
        """
        åˆ é™¤ç´¢å¼•
        
        Args:
            name: ç´¢å¼•åç§°
            
        Example:
            >>> manager.delete_index("old_index")
        """
        index_path = self._get_index_path(name)
        
        if not index_path.exists():
            logger.warning(f"ç´¢å¼•ä¸å­˜åœ¨: {name}")
            return
        
        logger.info(f"ðŸ—‘ï¸  åˆ é™¤ç´¢å¼•: {name}")
        
        try:
            delete_vector_store(str(index_path))
            logger.info(f"âœ… ç´¢å¼•åˆ é™¤æˆåŠŸ: {name}")
            
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤ç´¢å¼•å¤±è´¥: {e}")
            raise
    
    def list_indexes(self) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºæ‰€æœ‰ç´¢å¼•
        
        Returns:
            ç´¢å¼•ä¿¡æ¯åˆ—è¡¨
            
        Example:
            >>> indexes = manager.list_indexes()
            >>> for idx in indexes:
            ...     print(f"{idx['name']}: {idx['description']}")
        """
        logger.info("ðŸ“‹ åˆ—å‡ºæ‰€æœ‰ç´¢å¼•")
        
        indexes = []
        
        # éåŽ†ç´¢å¼•ç›®å½•
        if not self.base_path.exists():
            return indexes
        
        for index_dir in self.base_path.iterdir():
            if not index_dir.is_dir():
                continue
            
            name = index_dir.name
            metadata = self._load_metadata(name)
            
            if metadata:
                indexes.append(metadata)
            else:
                # å¦‚æžœæ²¡æœ‰å…ƒæ•°æ®ï¼Œåˆ›å»ºåŸºæœ¬ä¿¡æ¯
                indexes.append({
                    "name": name,
                    "description": "N/A",
                    "created_at": "N/A",
                    "updated_at": "N/A",
                    "num_documents": "N/A",
                })
        
        logger.info(f"   æ‰¾åˆ° {len(indexes)} ä¸ªç´¢å¼•")
        return indexes
    
    def get_index_info(self, name: str) -> Optional[Dict[str, Any]]:
        """
        èŽ·å–ç´¢å¼•è¯¦ç»†ä¿¡æ¯
        
        Args:
            name: ç´¢å¼•åç§°
            
        Returns:
            ç´¢å¼•ä¿¡æ¯å­—å…¸ï¼Œå¦‚æžœä¸å­˜åœ¨è¿”å›ž None
            
        Example:
            >>> info = manager.get_index_info("my_docs")
            >>> print(info)
        """
        index_path = self._get_index_path(name)
        
        if not index_path.exists():
            logger.warning(f"ç´¢å¼•ä¸å­˜åœ¨: {name}")
            return None
        
        # åŠ è½½å…ƒæ•°æ®
        metadata = self._load_metadata(name)
        
        if not metadata:
            metadata = {
                "name": name,
                "description": "N/A",
            }
        
        # æ·»åŠ è·¯å¾„ä¿¡æ¯
        metadata["path"] = str(index_path)
        
        # è®¡ç®—ç´¢å¼•å¤§å°
        try:
            total_size = sum(
                f.stat().st_size
                for f in index_path.rglob("*")
                if f.is_file()
            )
            metadata["size_bytes"] = total_size
            metadata["size_mb"] = total_size / (1024 * 1024)
        except Exception as e:
            logger.warning(f"è®¡ç®—ç´¢å¼•å¤§å°å¤±è´¥: {e}")
        
        return metadata
    
    def index_exists(self, name: str) -> bool:
        """
        æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
        
        Args:
            name: ç´¢å¼•åç§°
            
        Returns:
            æ˜¯å¦å­˜åœ¨
            
        Example:
            >>> if manager.index_exists("my_docs"):
            ...     print("ç´¢å¼•å­˜åœ¨")
        """
        return self._get_index_path(name).exists()

