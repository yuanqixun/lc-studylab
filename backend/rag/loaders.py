"""
æ–‡æ¡£åŠ è½½å™¨æ¨¡å—

æä¾›ç»Ÿä¸€çš„æ–‡æ¡£åŠ è½½æ¥å£ï¼Œæ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼š
- PDF (.pdf)
- Markdown (.md, .mdx)
- æ–‡æœ¬æ–‡ä»¶ (.txt)
- HTML (.html, .htm)
- JSON (.json)

ä½¿ç”¨ LangChain çš„ Document Loaders APIã€‚

å‚è€ƒï¼š
- https://reference.langchain.com/python/langchain_core/document_loaders/
- https://reference.langchain.com/python/langchain_community/document_loaders/
"""

import os
from pathlib import Path
from typing import List, Optional, Dict, Any
from langchain_core.documents import Document
from langchain_community.document_loaders import (
    PyPDFLoader,
    TextLoader,
    UnstructuredMarkdownLoader,
    UnstructuredHTMLLoader,
    JSONLoader,
    DirectoryLoader,
)

from config import get_logger

logger = get_logger(__name__)


# æ”¯æŒçš„æ–‡ä»¶æ‰©å±•åæ˜ å°„
SUPPORTED_EXTENSIONS = {
    ".pdf": "pdf",
    ".txt": "text",
    ".md": "markdown",
    ".mdx": "markdown",
    ".html": "html",
    ".htm": "html",
    ".json": "json",
}


def get_supported_extensions() -> Dict[str, str]:
    """
    è·å–æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
    
    Returns:
        æ‰©å±•ååˆ°ç±»å‹çš„æ˜ å°„å­—å…¸
        
    Example:
        >>> extensions = get_supported_extensions()
        >>> print(extensions)
        {'.pdf': 'pdf', '.txt': 'text', ...}
    """
    return SUPPORTED_EXTENSIONS.copy()


def get_loader_for_file(file_path: str) -> Optional[Any]:
    """
    æ ¹æ®æ–‡ä»¶ç±»å‹è·å–åˆé€‚çš„æ–‡æ¡£åŠ è½½å™¨
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        
    Returns:
        å¯¹åº”çš„ Loader å®ä¾‹ï¼Œå¦‚æœä¸æ”¯æŒåˆ™è¿”å› None
        
    Example:
        >>> loader = get_loader_for_file("document.pdf")
        >>> documents = loader.load()
    """
    file_path = Path(file_path)
    extension = file_path.suffix.lower()
    
    if extension not in SUPPORTED_EXTENSIONS:
        logger.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {extension}, æ–‡ä»¶: {file_path}")
        return None
    
    file_type = SUPPORTED_EXTENSIONS[extension]
    
    try:
        if file_type == "pdf":
            return PyPDFLoader(str(file_path))
        elif file_type == "text":
            return TextLoader(str(file_path), encoding="utf-8")
        elif file_type == "markdown":
            return UnstructuredMarkdownLoader(str(file_path))
        elif file_type == "html":
            return UnstructuredHTMLLoader(str(file_path))
        elif file_type == "json":
            # JSON åŠ è½½å™¨éœ€è¦æŒ‡å®š jq_schema æ¥æå–å†…å®¹
            # é»˜è®¤æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
            return JSONLoader(
                file_path=str(file_path),
                jq_schema=".",
                text_content=False,
            )
        else:
            logger.warning(f"æœªå®ç°çš„æ–‡ä»¶ç±»å‹å¤„ç†: {file_type}")
            return None
            
    except Exception as e:
        logger.error(f"åˆ›å»ºåŠ è½½å™¨å¤±è´¥: {file_path}, é”™è¯¯: {e}")
        return None


def load_document(
    file_path: str,
    add_metadata: bool = True,
) -> List[Document]:
    """
    åŠ è½½å•ä¸ªæ–‡æ¡£
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        add_metadata: æ˜¯å¦æ·»åŠ é¢å¤–çš„å…ƒæ•°æ®ï¼ˆæ–‡ä»¶åã€è·¯å¾„ç­‰ï¼‰
        
    Returns:
        Document å¯¹è±¡åˆ—è¡¨
        
    Raises:
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
        ValueError: ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        
    Example:
        >>> documents = load_document("document.pdf")
        >>> print(f"åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£å—")
        >>> print(documents[0].page_content[:100])
    """
    file_path = Path(file_path)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not file_path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶
    if not file_path.is_file():
        raise ValueError(f"ä¸æ˜¯æ–‡ä»¶: {file_path}")
    
    # è·å–åŠ è½½å™¨
    loader = get_loader_for_file(str(file_path))
    if loader is None:
        extension = file_path.suffix.lower()
        supported = ", ".join(SUPPORTED_EXTENSIONS.keys())
        raise ValueError(
            f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {extension}ã€‚"
            f"æ”¯æŒçš„ç±»å‹: {supported}"
        )
    
    # åŠ è½½æ–‡æ¡£
    try:
        logger.info(f"ğŸ“„ åŠ è½½æ–‡æ¡£: {file_path}")
        documents = loader.load()
        
        # æ·»åŠ é¢å¤–çš„å…ƒæ•°æ®
        if add_metadata:
            for doc in documents:
                if doc.metadata is None:
                    doc.metadata = {}
                doc.metadata.update({
                    "source": str(file_path),
                    "filename": file_path.name,
                    "file_type": SUPPORTED_EXTENSIONS[file_path.suffix.lower()],
                })
        
        logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£å—")
        return documents
        
    except Exception as e:
        logger.error(f"âŒ åŠ è½½æ–‡æ¡£å¤±è´¥: {file_path}, é”™è¯¯: {e}")
        raise


def load_directory(
    directory_path: str,
    glob_pattern: str = "**/*",
    exclude_patterns: Optional[List[str]] = None,
    recursive: bool = True,
    show_progress: bool = True,
    max_files: Optional[int] = None,
) -> List[Document]:
    """
    æ‰¹é‡åŠ è½½ç›®å½•ä¸­çš„æ–‡æ¡£
    
    Args:
        directory_path: ç›®å½•è·¯å¾„
        glob_pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼Œé»˜è®¤åŒ¹é…æ‰€æœ‰æ–‡ä»¶
        exclude_patterns: æ’é™¤çš„æ–‡ä»¶æ¨¡å¼åˆ—è¡¨
        recursive: æ˜¯å¦é€’å½’åŠ è½½å­ç›®å½•
        show_progress: æ˜¯å¦æ˜¾ç¤ºåŠ è½½è¿›åº¦
        max_files: æœ€å¤§åŠ è½½æ–‡ä»¶æ•°ï¼ŒNone è¡¨ç¤ºæ— é™åˆ¶
        
    Returns:
        Document å¯¹è±¡åˆ—è¡¨
        
    Raises:
        FileNotFoundError: ç›®å½•ä¸å­˜åœ¨
        ValueError: ä¸æ˜¯ç›®å½•
        
    Example:
        >>> # åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰ Markdown æ–‡ä»¶
        >>> documents = load_directory(
        ...     "docs/",
        ...     glob_pattern="**/*.md"
        ... )
        >>> 
        >>> # æ’é™¤æŸäº›æ–‡ä»¶
        >>> documents = load_directory(
        ...     "docs/",
        ...     exclude_patterns=["**/draft/*", "**/.git/*"]
        ... )
    """
    directory_path = Path(directory_path)
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not directory_path.exists():
        raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {directory_path}")
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºç›®å½•
    if not directory_path.is_dir():
        raise ValueError(f"ä¸æ˜¯ç›®å½•: {directory_path}")
    
    logger.info(f"ğŸ“ å¼€å§‹åŠ è½½ç›®å½•: {directory_path}")
    logger.info(f"   åŒ¹é…æ¨¡å¼: {glob_pattern}")
    if exclude_patterns:
        logger.info(f"   æ’é™¤æ¨¡å¼: {exclude_patterns}")
    
    # æ”¶é›†æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶
    all_files = []
    for ext in SUPPORTED_EXTENSIONS.keys():
        pattern = f"**/*{ext}" if recursive else f"*{ext}"
        files = list(directory_path.glob(pattern))
        all_files.extend(files)
    
    # åº”ç”¨æ’é™¤æ¨¡å¼
    if exclude_patterns:
        filtered_files = []
        for file in all_files:
            should_exclude = False
            for pattern in exclude_patterns:
                if file.match(pattern):
                    should_exclude = True
                    break
            if not should_exclude:
                filtered_files.append(file)
        all_files = filtered_files
    
    # é™åˆ¶æ–‡ä»¶æ•°é‡
    if max_files is not None and len(all_files) > max_files:
        logger.warning(f"âš ï¸  æ–‡ä»¶æ•°é‡ ({len(all_files)}) è¶…è¿‡é™åˆ¶ ({max_files})ï¼ŒåªåŠ è½½å‰ {max_files} ä¸ª")
        all_files = all_files[:max_files]
    
    logger.info(f"   æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶")
    
    # é€ä¸ªåŠ è½½æ–‡ä»¶
    all_documents = []
    success_count = 0
    error_count = 0
    
    for i, file_path in enumerate(all_files, 1):
        try:
            if show_progress:
                logger.info(f"   [{i}/{len(all_files)}] åŠ è½½: {file_path.name}")
            
            documents = load_document(str(file_path), add_metadata=True)
            all_documents.extend(documents)
            success_count += 1
            
        except Exception as e:
            logger.error(f"   âŒ åŠ è½½å¤±è´¥: {file_path.name}, é”™è¯¯: {e}")
            error_count += 1
            continue
    
    logger.info(f"âœ… ç›®å½•åŠ è½½å®Œæˆ:")
    logger.info(f"   æˆåŠŸ: {success_count} ä¸ªæ–‡ä»¶")
    logger.info(f"   å¤±è´¥: {error_count} ä¸ªæ–‡ä»¶")
    logger.info(f"   æ€»è®¡: {len(all_documents)} ä¸ªæ–‡æ¡£å—")
    
    return all_documents


def load_documents_from_paths(
    file_paths: List[str],
    show_progress: bool = True,
) -> List[Document]:
    """
    ä»æ–‡ä»¶è·¯å¾„åˆ—è¡¨åŠ è½½æ–‡æ¡£
    
    Args:
        file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        show_progress: æ˜¯å¦æ˜¾ç¤ºåŠ è½½è¿›åº¦
        
    Returns:
        Document å¯¹è±¡åˆ—è¡¨
        
    Example:
        >>> paths = ["doc1.pdf", "doc2.md", "doc3.txt"]
        >>> documents = load_documents_from_paths(paths)
    """
    logger.info(f"ğŸ“š å¼€å§‹åŠ è½½ {len(file_paths)} ä¸ªæ–‡ä»¶")
    
    all_documents = []
    success_count = 0
    error_count = 0
    
    for i, file_path in enumerate(file_paths, 1):
        try:
            if show_progress:
                logger.info(f"   [{i}/{len(file_paths)}] åŠ è½½: {Path(file_path).name}")
            
            documents = load_document(file_path, add_metadata=True)
            all_documents.extend(documents)
            success_count += 1
            
        except Exception as e:
            logger.error(f"   âŒ åŠ è½½å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            error_count += 1
            continue
    
    logger.info(f"âœ… æ‰¹é‡åŠ è½½å®Œæˆ:")
    logger.info(f"   æˆåŠŸ: {success_count} ä¸ªæ–‡ä»¶")
    logger.info(f"   å¤±è´¥: {error_count} ä¸ªæ–‡ä»¶")
    logger.info(f"   æ€»è®¡: {len(all_documents)} ä¸ªæ–‡æ¡£å—")
    
    return all_documents

