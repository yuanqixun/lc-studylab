{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ç¬¬ 4 é˜¶æ®µï¼šDeepAgents æ·±åº¦ç ”ç©¶\n",
                "\n",
                "æœ¬ Notebook ç”¨äºå­¦ä¹ å’Œè°ƒè¯•ç¬¬ 4 é˜¶æ®µçš„æ ¸å¿ƒåŠŸèƒ½ï¼š\n",
                "- DeepAgent æ·±åº¦ç ”ç©¶æ¶æ„\n",
                "- å¤šä»£ç†åä½œï¼ˆæœç´¢ã€åˆ†æã€æ€»ç»“ï¼‰\n",
                "- ç½‘ç»œæœç´¢é›†æˆ\n",
                "- æ–‡æ¡£åˆ†æé›†æˆ\n",
                "- æ–‡ä»¶ç³»ç»Ÿç®¡ç†\n",
                "- ç ”ç©¶æŠ¥å‘Šç”Ÿæˆ\n",
                "\n",
                "**å‚è€ƒæ–‡æ¡£**: `docs/stage_04/`ï¼ˆè®¡åˆ’ä¸­ï¼‰  \n",
                "**å‚è€ƒè„šæœ¬**: `scripts/test_deep_research.py`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ç¯å¢ƒå‡†å¤‡"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "backend_dir = Path.cwd()\n",
                "if backend_dir.name == 'notebooks':\n",
                "    backend_dir = backend_dir.parent\n",
                "\n",
                "if str(backend_dir) not in sys.path:\n",
                "    sys.path.insert(0, str(backend_dir))\n",
                "\n",
                "print(f\"âœ… é¡¹ç›®æ ¹ç›®å½•: {backend_dir}\")\n",
                "\n",
                "# å¯¼å…¥å¿…è¦çš„æ¨¡å—\n",
                "import time\n",
                "import uuid\n",
                "from config import settings, get_logger\n",
                "\n",
                "logger = get_logger(__name__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. æ£€æŸ¥é…ç½®"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\né…ç½®æ£€æŸ¥\")\n",
                "print(\"=\"*60)\n",
                "print(f\"OpenAI API: {'âœ… å·²é…ç½®' if settings.openai_api_key else 'âŒ æœªé…ç½®'}\")\n",
                "print(f\"Tavily API: {'âœ… å·²é…ç½®' if settings.tavily_api_key else 'âŒ æœªé…ç½®'}\")\n",
                "print(f\"æ¨¡å‹: {settings.openai_model}\")\n",
                "print(f\"æ•°æ®ç›®å½•: {settings.DATA_DIR}\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "if not settings.tavily_api_key:\n",
                "    print(\"\\nâš ï¸  è­¦å‘Š: æœªé…ç½® TAVILY_API_KEYï¼Œç½‘ç»œæœç´¢åŠŸèƒ½å°†ä¸å¯ç”¨\")\n",
                "    print(\"   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® TAVILY_API_KEY\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. æ–‡ä»¶ç³»ç»ŸåŠŸèƒ½"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1 åˆ›å»ºæ–‡ä»¶ç³»ç»Ÿ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from core.tools.filesystem import get_filesystem\n",
                "\n",
                "# åˆ›å»ºæ–‡ä»¶ç³»ç»Ÿå®ä¾‹\n",
                "thread_id = f\"notebook_fs_{uuid.uuid4().hex[:8]}\"\n",
                "fs = get_filesystem(thread_id)\n",
                "\n",
                "print(f\"âœ… æ–‡ä»¶ç³»ç»Ÿåˆ›å»ºæˆåŠŸ\")\n",
                "print(f\"   Thread ID: {thread_id}\")\n",
                "print(f\"   å·¥ä½œç©ºé—´: {fs.workspace_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 å†™å…¥æ–‡ä»¶"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# å†™å…¥æµ‹è¯•æ–‡ä»¶\n",
                "test_content = \"\"\"# ç ”ç©¶ç¬”è®°\n",
                "\n",
                "## ä¸»é¢˜\n",
                "LangChain 1.0 æ–°ç‰¹æ€§ç ”ç©¶\n",
                "\n",
                "## å…³é”®å‘ç°\n",
                "1. æ”¹è¿›çš„ Agent æ¶æ„\n",
                "2. æ›´å¥½çš„æµå¼è¾“å‡ºæ”¯æŒ\n",
                "3. å¢å¼ºçš„å·¥å…·è°ƒç”¨èƒ½åŠ›\n",
                "\n",
                "## å‚è€ƒèµ„æ–™\n",
                "- LangChain å®˜æ–¹æ–‡æ¡£\n",
                "- GitHub Release Notes\n",
                "\"\"\"\n",
                "\n",
                "# å†™å…¥åˆ° notes å­ç›®å½•\n",
                "fs.write_file(\n",
                "    filename=\"research_note.md\",\n",
                "    content=test_content,\n",
                "    subdirectory=\"notes\"\n",
                ")\n",
                "\n",
                "print(\"âœ… æ–‡ä»¶å†™å…¥æˆåŠŸ: notes/research_note.md\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 è¯»å–æ–‡ä»¶"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# è¯»å–æ–‡ä»¶\n",
                "content = fs.read_file(\"research_note.md\", subdirectory=\"notes\")\n",
                "\n",
                "print(\"ğŸ“„ æ–‡ä»¶å†…å®¹:\")\n",
                "print(\"=\"*60)\n",
                "print(content)\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.4 åˆ—å‡ºæ–‡ä»¶"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶\n",
                "files = fs.list_files()\n",
                "\n",
                "print(f\"\\nğŸ“š å·¥ä½œç©ºé—´æ–‡ä»¶åˆ—è¡¨ ({len(files)} ä¸ª):\")\n",
                "for f in files:\n",
                "    print(f\"  - {f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.5 æœç´¢æ–‡ä»¶"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æœç´¢åŒ…å«ç‰¹å®šå…³é”®è¯çš„æ–‡ä»¶\n",
                "search_results = fs.search_files(\"LangChain\")\n",
                "\n",
                "print(f\"\\nğŸ” æœç´¢ç»“æœ (å…³é”®è¯: 'LangChain'):\")\n",
                "print(f\"æ‰¾åˆ° {len(search_results)} ä¸ªåŒ¹é…æ–‡ä»¶:\")\n",
                "for result in search_results:\n",
                "    print(f\"  - {result}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.6 åˆ é™¤æ–‡ä»¶"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# åˆ é™¤æµ‹è¯•æ–‡ä»¶\n",
                "# fs.delete_file(\"research_note.md\", subdirectory=\"notes\")\n",
                "# print(\"âœ… æ–‡ä»¶å·²åˆ é™¤\")\n",
                "\n",
                "print(\"âš ï¸  å–æ¶ˆæ³¨é‡Šä¸Šé¢çš„ä»£ç ä»¥åˆ é™¤æ–‡ä»¶\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. DeepAgent åŸºç¡€ç ”ç©¶"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 åˆ›å»º DeepAgentï¼ˆä»…ç½‘ç»œæœç´¢ï¼‰"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deep_research import create_deep_research_agent\n",
                "\n",
                "# æ£€æŸ¥ Tavily API Key\n",
                "if not settings.tavily_api_key:\n",
                "    print(\"âŒ æœªé…ç½® TAVILY_API_KEYï¼Œæ— æ³•ä½¿ç”¨ç½‘ç»œæœç´¢åŠŸèƒ½\")\n",
                "    print(\"   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® TAVILY_API_KEY\")\n",
                "else:\n",
                "    # åˆ›å»º DeepAgent\n",
                "    research_thread_id = f\"research_{uuid.uuid4().hex[:8]}\"\n",
                "    \n",
                "    agent = create_deep_research_agent(\n",
                "        thread_id=research_thread_id,\n",
                "        enable_web_search=True,\n",
                "        enable_doc_analysis=False,\n",
                "    )\n",
                "    \n",
                "    print(f\"âœ… DeepAgent åˆ›å»ºæˆåŠŸ\")\n",
                "    print(f\"   Thread ID: {research_thread_id}\")\n",
                "    print(f\"   ç½‘ç»œæœç´¢: å¯ç”¨\")\n",
                "    print(f\"   æ–‡æ¡£åˆ†æ: ç¦ç”¨\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 æ‰§è¡ŒåŸºç¡€ç ”ç©¶"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# å®šä¹‰ç ”ç©¶é—®é¢˜\n",
                "query = \"LangChain 1.0 æœ‰å“ªäº›ä¸»è¦æ–°ç‰¹æ€§ï¼Ÿ\"\n",
                "\n",
                "print(f\"\\nğŸ”¬ ç ”ç©¶é—®é¢˜: {query}\")\n",
                "print(\"\\nâ³ æ­£åœ¨æ‰§è¡Œç ”ç©¶ä»»åŠ¡ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...\\n\")\n",
                "\n",
                "if settings.tavily_api_key:\n",
                "    start_time = time.time()\n",
                "    \n",
                "    # æ‰§è¡Œç ”ç©¶\n",
                "    result = agent.research(query)\n",
                "    \n",
                "    elapsed_time = time.time() - start_time\n",
                "    \n",
                "    print(f\"\\nâœ… ç ”ç©¶å®Œæˆï¼è€—æ—¶: {elapsed_time:.1f} ç§’\\n\")\n",
                "else:\n",
                "    print(\"âš ï¸  è·³è¿‡ç ”ç©¶ï¼ˆéœ€è¦ Tavily API Keyï¼‰\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 æŸ¥çœ‹ç ”ç©¶è®¡åˆ’"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if settings.tavily_api_key and result.get(\"plan\"):\n",
                "    plan = result[\"plan\"]\n",
                "    \n",
                "    print(\"\\nğŸ“‹ ç ”ç©¶è®¡åˆ’\")\n",
                "    print(\"=\"*60)\n",
                "    print(f\"ç ”ç©¶ç›®æ ‡: {plan.get('research_goal', 'N/A')}\")\n",
                "    \n",
                "    if plan.get('search_keywords'):\n",
                "        print(f\"\\næœç´¢å…³é”®è¯:\")\n",
                "        for kw in plan['search_keywords']:\n",
                "            print(f\"  - {kw}\")\n",
                "    \n",
                "    if plan.get('analysis_steps'):\n",
                "        print(f\"\\nåˆ†ææ­¥éª¤:\")\n",
                "        for i, step in enumerate(plan['analysis_steps'], 1):\n",
                "            print(f\"  {i}. {step}\")\n",
                "    \n",
                "    print(\"=\"*60)\n",
                "else:\n",
                "    print(\"âš ï¸  æœªè·å–åˆ°ç ”ç©¶è®¡åˆ’\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.4 æŸ¥çœ‹å®Œæˆçš„æ­¥éª¤"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if settings.tavily_api_key and result.get(\"steps_completed\"):\n",
                "    steps = result[\"steps_completed\"]\n",
                "    \n",
                "    print(\"\\nâœ… å®Œæˆçš„æ­¥éª¤\")\n",
                "    print(\"=\"*60)\n",
                "    for step, completed in steps.items():\n",
                "        status = \"âœ…\" if completed else \"âŒ\"\n",
                "        print(f\"{status} {step}\")\n",
                "    print(\"=\"*60)\n",
                "else:\n",
                "    print(\"âš ï¸  æœªè·å–åˆ°æ­¥éª¤ä¿¡æ¯\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.5 æŸ¥çœ‹æœ€ç»ˆæŠ¥å‘Š"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if settings.tavily_api_key and result.get(\"final_report\"):\n",
                "    report = result[\"final_report\"]\n",
                "    \n",
                "    print(\"\\nğŸ“Š æœ€ç»ˆç ”ç©¶æŠ¥å‘Š\")\n",
                "    print(\"=\"*60)\n",
                "    print(report)\n",
                "    print(\"=\"*60)\n",
                "else:\n",
                "    print(\"âš ï¸  æœªç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.6 æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if settings.tavily_api_key:\n",
                "    # è·å–ç ”ç©¶å·¥ä½œç©ºé—´çš„æ–‡ä»¶ç³»ç»Ÿ\n",
                "    research_fs = get_filesystem(research_thread_id)\n",
                "    files = research_fs.list_files()\n",
                "    \n",
                "    print(f\"\\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶ ({len(files)} ä¸ª):\")\n",
                "    print(\"=\"*60)\n",
                "    for f in files:\n",
                "        print(f\"  ğŸ“„ {f}\")\n",
                "    print(\"=\"*60)\n",
                "else:\n",
                "    print(\"âš ï¸  è·³è¿‡æ–‡ä»¶æŸ¥çœ‹\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. DeepAgent å®Œæ•´ç ”ç©¶ï¼ˆç½‘ç»œ + æ–‡æ¡£ï¼‰"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.1 å‡†å¤‡æ–‡æ¡£ç´¢å¼•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ç´¢å¼•\n",
                "from pathlib import Path\n",
                "\n",
                "index_path = Path(settings.vector_store_path) / \"test_index\"\n",
                "\n",
                "if index_path.exists():\n",
                "    print(f\"âœ… æ‰¾åˆ°æµ‹è¯•ç´¢å¼•: {index_path}\")\n",
                "    has_index = True\n",
                "else:\n",
                "    print(f\"âš ï¸  æœªæ‰¾åˆ°æµ‹è¯•ç´¢å¼•: {index_path}\")\n",
                "    print(\"   è¯·å…ˆè¿è¡Œ RAG ç´¢å¼•æ„å»º:\")\n",
                "    print(\"   python scripts/update_index.py --collection test_index --path data/documents/test\")\n",
                "    has_index = False"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 åŠ è½½æ–‡æ¡£æ£€ç´¢å™¨"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if has_index:\n",
                "    from rag import get_embeddings, load_vector_store, create_retriever_tool\n",
                "    \n",
                "    print(\"ğŸ”„ åŠ è½½æ–‡æ¡£ç´¢å¼•...\")\n",
                "    \n",
                "    # åŠ è½½ embedding å’Œå‘é‡å­˜å‚¨\n",
                "    embeddings = get_embeddings()\n",
                "    vector_store = load_vector_store(str(index_path), embeddings)\n",
                "    \n",
                "    # åˆ›å»ºæ£€ç´¢å™¨å·¥å…·\n",
                "    retriever = vector_store.as_retriever()\n",
                "    retriever_tool = create_retriever_tool(retriever)\n",
                "    \n",
                "    print(\"âœ… æ–‡æ¡£ç´¢å¼•åŠ è½½æˆåŠŸ\")\n",
                "else:\n",
                "    print(\"âš ï¸  è·³è¿‡æ–‡æ¡£åŠ è½½\")\n",
                "    retriever_tool = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.3 åˆ›å»ºå®Œæ•´ DeepAgent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if has_index and settings.tavily_api_key:\n",
                "    # åˆ›å»ºå®Œæ•´çš„ DeepAgentï¼ˆç½‘ç»œæœç´¢ + æ–‡æ¡£åˆ†æï¼‰\n",
                "    full_thread_id = f\"full_research_{uuid.uuid4().hex[:8]}\"\n",
                "    \n",
                "    full_agent = create_deep_research_agent(\n",
                "        thread_id=full_thread_id,\n",
                "        enable_web_search=True,\n",
                "        enable_doc_analysis=True,\n",
                "        retriever_tool=retriever_tool,\n",
                "    )\n",
                "    \n",
                "    print(f\"âœ… å®Œæ•´ DeepAgent åˆ›å»ºæˆåŠŸ\")\n",
                "    print(f\"   Thread ID: {full_thread_id}\")\n",
                "    print(f\"   ç½‘ç»œæœç´¢: å¯ç”¨\")\n",
                "    print(f\"   æ–‡æ¡£åˆ†æ: å¯ç”¨\")\n",
                "else:\n",
                "    print(\"âš ï¸  è·³è¿‡å®Œæ•´ DeepAgent åˆ›å»ºï¼ˆéœ€è¦ç´¢å¼•å’Œ Tavily API Keyï¼‰\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.4 æ‰§è¡Œå®Œæ•´ç ”ç©¶"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if has_index and settings.tavily_api_key:\n",
                "    # å®šä¹‰ç ”ç©¶é—®é¢˜\n",
                "    full_query = \"ä»€ä¹ˆæ˜¯ RAGï¼Ÿå®ƒæœ‰å“ªäº›åº”ç”¨åœºæ™¯ï¼Ÿ\"\n",
                "    \n",
                "    print(f\"\\nğŸ”¬ ç ”ç©¶é—®é¢˜: {full_query}\")\n",
                "    print(\"\\nâ³ æ­£åœ¨æ‰§è¡Œå®Œæ•´ç ”ç©¶ä»»åŠ¡ï¼ˆç½‘ç»œ + æ–‡æ¡£ï¼‰ï¼Œè¿™å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´...\\n\")\n",
                "    \n",
                "    start_time = time.time()\n",
                "    \n",
                "    # æ‰§è¡Œç ”ç©¶\n",
                "    full_result = full_agent.research(full_query)\n",
                "    \n",
                "    elapsed_time = time.time() - start_time\n",
                "    \n",
                "    print(f\"\\nâœ… å®Œæ•´ç ”ç©¶å®Œæˆï¼è€—æ—¶: {elapsed_time:.1f} ç§’\\n\")\n",
                "else:\n",
                "    print(\"âš ï¸  è·³è¿‡å®Œæ•´ç ”ç©¶\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.5 æŸ¥çœ‹å®Œæ•´ç ”ç©¶ç»“æœ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if has_index and settings.tavily_api_key:\n",
                "    # æ˜¾ç¤ºå®Œæˆçš„æ­¥éª¤\n",
                "    print(\"\\nâœ… å®Œæˆçš„æ­¥éª¤\")\n",
                "    print(\"=\"*60)\n",
                "    steps = full_result.get(\"steps_completed\", {})\n",
                "    for step, completed in steps.items():\n",
                "        status = \"âœ… å®Œæˆ\" if completed else \"âŒ æœªå®Œæˆ\"\n",
                "        print(f\"{status} - {step}\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    # æ˜¾ç¤ºæœ€ç»ˆæŠ¥å‘Š\n",
                "    if full_result.get(\"final_report\"):\n",
                "        print(\"\\nğŸ“Š æœ€ç»ˆç ”ç©¶æŠ¥å‘Š\")\n",
                "        print(\"=\"*60)\n",
                "        print(full_result[\"final_report\"])\n",
                "        print(\"=\"*60)\n",
                "    \n",
                "    # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶\n",
                "    full_fs = get_filesystem(full_thread_id)\n",
                "    files = full_fs.list_files()\n",
                "    \n",
                "    print(f\"\\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶ ({len(files)} ä¸ª):\")\n",
                "    for f in files:\n",
                "        print(f\"  ğŸ“„ {f}\")\n",
                "else:\n",
                "    print(\"âš ï¸  è·³è¿‡ç»“æœæŸ¥çœ‹\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. ç ”ç©¶ç»“æœåˆ†æ"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.1 è¯»å–ç ”ç©¶æŠ¥å‘Šæ–‡ä»¶"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if settings.tavily_api_key:\n",
                "    # è¯»å–æœ€ç»ˆæŠ¥å‘Šæ–‡ä»¶\n",
                "    research_fs = get_filesystem(research_thread_id)\n",
                "    \n",
                "    try:\n",
                "        # å°è¯•è¯»å–æœ€ç»ˆæŠ¥å‘Š\n",
                "        report_content = research_fs.read_file(\"final_report.md\")\n",
                "        \n",
                "        print(\"\\nğŸ“„ æœ€ç»ˆæŠ¥å‘Šæ–‡ä»¶å†…å®¹\")\n",
                "        print(\"=\"*60)\n",
                "        print(report_content)\n",
                "        print(\"=\"*60)\n",
                "    except Exception as e:\n",
                "        print(f\"âš ï¸  æ— æ³•è¯»å–æŠ¥å‘Šæ–‡ä»¶: {e}\")\n",
                "else:\n",
                "    print(\"âš ï¸  è·³è¿‡æŠ¥å‘Šè¯»å–\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.2 åˆ†æç ”ç©¶æ•°æ®"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if settings.tavily_api_key and result:\n",
                "    print(\"\\nğŸ“ˆ ç ”ç©¶æ•°æ®åˆ†æ\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    # ç»Ÿè®¡ä¿¡æ¯\n",
                "    print(f\"ç ”ç©¶é—®é¢˜: {query}\")\n",
                "    print(f\"è€—æ—¶: {elapsed_time:.1f} ç§’\")\n",
                "    \n",
                "    # æ­¥éª¤å®Œæˆæƒ…å†µ\n",
                "    steps = result.get(\"steps_completed\", {})\n",
                "    completed_count = sum(1 for v in steps.values() if v)\n",
                "    total_count = len(steps)\n",
                "    \n",
                "    print(f\"\\næ­¥éª¤å®Œæˆ: {completed_count}/{total_count}\")\n",
                "    \n",
                "    # æ–‡ä»¶ç”Ÿæˆæƒ…å†µ\n",
                "    research_fs = get_filesystem(research_thread_id)\n",
                "    files = research_fs.list_files()\n",
                "    \n",
                "    print(f\"ç”Ÿæˆæ–‡ä»¶æ•°: {len(files)}\")\n",
                "    \n",
                "    # æŠ¥å‘Šé•¿åº¦\n",
                "    if result.get(\"final_report\"):\n",
                "        report_length = len(result[\"final_report\"])\n",
                "        print(f\"æŠ¥å‘Šé•¿åº¦: {report_length} å­—ç¬¦\")\n",
                "    \n",
                "    print(\"=\"*60)\n",
                "else:\n",
                "    print(\"âš ï¸  è·³è¿‡æ•°æ®åˆ†æ\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. è‡ªå®šä¹‰ç ”ç©¶ä»»åŠ¡"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_custom_research(query: str, enable_web: bool = True, enable_doc: bool = False):\n",
                "    \"\"\"è¿è¡Œè‡ªå®šä¹‰ç ”ç©¶ä»»åŠ¡\"\"\"\n",
                "    \n",
                "    if not settings.tavily_api_key and enable_web:\n",
                "        print(\"âŒ éœ€è¦ Tavily API Key æ‰èƒ½ä½¿ç”¨ç½‘ç»œæœç´¢\")\n",
                "        return None\n",
                "    \n",
                "    # åˆ›å»º thread_id\n",
                "    custom_thread_id = f\"custom_{uuid.uuid4().hex[:8]}\"\n",
                "    \n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"è‡ªå®šä¹‰ç ”ç©¶ä»»åŠ¡\")\n",
                "    print(f\"{'='*60}\")\n",
                "    print(f\"Thread ID: {custom_thread_id}\")\n",
                "    print(f\"é—®é¢˜: {query}\")\n",
                "    print(f\"ç½‘ç»œæœç´¢: {'å¯ç”¨' if enable_web else 'ç¦ç”¨'}\")\n",
                "    print(f\"æ–‡æ¡£åˆ†æ: {'å¯ç”¨' if enable_doc else 'ç¦ç”¨'}\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    # åˆ›å»º agent\n",
                "    agent = create_deep_research_agent(\n",
                "        thread_id=custom_thread_id,\n",
                "        enable_web_search=enable_web,\n",
                "        enable_doc_analysis=enable_doc,\n",
                "        retriever_tool=retriever_tool if enable_doc and has_index else None,\n",
                "    )\n",
                "    \n",
                "    print(\"â³ ç ”ç©¶ä¸­...\\n\")\n",
                "    \n",
                "    # æ‰§è¡Œç ”ç©¶\n",
                "    start = time.time()\n",
                "    result = agent.research(query)\n",
                "    elapsed = time.time() - start\n",
                "    \n",
                "    print(f\"\\nâœ… ç ”ç©¶å®Œæˆï¼è€—æ—¶: {elapsed:.1f} ç§’\\n\")\n",
                "    \n",
                "    # æ˜¾ç¤ºç»“æœ\n",
                "    if result.get(\"final_report\"):\n",
                "        print(\"ğŸ“Š ç ”ç©¶æŠ¥å‘Š:\")\n",
                "        print(\"=\"*60)\n",
                "        print(result[\"final_report\"][:500] + \"...\")\n",
                "        print(\"=\"*60)\n",
                "    \n",
                "    return result\n",
                "\n",
                "# ä½¿ç”¨ç¤ºä¾‹ï¼ˆå–æ¶ˆæ³¨é‡Šä»¥è¿è¡Œï¼‰\n",
                "# custom_result = run_custom_research(\n",
                "#     query=\"ä»€ä¹ˆæ˜¯ Transformer æ¶æ„ï¼Ÿ\",\n",
                "#     enable_web=True,\n",
                "#     enable_doc=False\n",
                "# )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. API é›†æˆç¤ºä¾‹"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 8.1 API ç«¯ç‚¹è¯´æ˜"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\"\"\n",
                "DeepAgent API ç«¯ç‚¹:\n",
                "\n",
                "1. å¯åŠ¨ç ”ç©¶ä»»åŠ¡:\n",
                "   POST /deep-research/start\n",
                "   Body: {\n",
                "     \"query\": \"ç ”ç©¶é—®é¢˜\",\n",
                "     \"enable_web_search\": true,\n",
                "     \"enable_doc_analysis\": false\n",
                "   }\n",
                "\n",
                "2. æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€:\n",
                "   GET /deep-research/status/{thread_id}\n",
                "\n",
                "3. è·å–ç ”ç©¶ç»“æœ:\n",
                "   GET /deep-research/result/{thread_id}\n",
                "\n",
                "4. åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶:\n",
                "   GET /deep-research/files/{thread_id}\n",
                "\n",
                "5. è¯»å–ç‰¹å®šæ–‡ä»¶:\n",
                "   GET /deep-research/file/{thread_id}/{filename}\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 8.2 ä½¿ç”¨ requests è°ƒç”¨ APIï¼ˆéœ€è¦å¯åŠ¨æœåŠ¡å™¨ï¼‰"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ç¤ºä¾‹ä»£ç ï¼ˆéœ€è¦å…ˆå¯åŠ¨ API æœåŠ¡å™¨ï¼‰\n",
                "print(\"\"\"\n",
                "ä½¿ç”¨ requests è°ƒç”¨ API çš„ç¤ºä¾‹ä»£ç :\n",
                "\n",
                "import requests\n",
                "\n",
                "# 1. å¯åŠ¨ç ”ç©¶\n",
                "response = requests.post(\n",
                "    \"http://localhost:8000/deep-research/start\",\n",
                "    json={\n",
                "        \"query\": \"LangChain 1.0 æ–°ç‰¹æ€§\",\n",
                "        \"enable_web_search\": True,\n",
                "        \"enable_doc_analysis\": False\n",
                "    }\n",
                ")\n",
                "thread_id = response.json()[\"thread_id\"]\n",
                "\n",
                "# 2. æŸ¥è¯¢çŠ¶æ€\n",
                "status = requests.get(f\"http://localhost:8000/deep-research/status/{thread_id}\")\n",
                "print(status.json())\n",
                "\n",
                "# 3. è·å–ç»“æœ\n",
                "result = requests.get(f\"http://localhost:8000/deep-research/result/{thread_id}\")\n",
                "print(result.json())\n",
                "\"\"\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. æ€»ç»“\n",
                "\n",
                "é€šè¿‡æœ¬ Notebookï¼Œä½ å·²ç»å­¦ä¹ äº†ï¼š\n",
                "\n",
                "âœ… DeepAgent æ·±åº¦ç ”ç©¶æ¶æ„  \n",
                "âœ… æ–‡ä»¶ç³»ç»Ÿç®¡ç†ï¼ˆè¯»å†™ã€æœç´¢ã€åˆ é™¤ï¼‰  \n",
                "âœ… åŸºç¡€ç ”ç©¶ï¼ˆç½‘ç»œæœç´¢ï¼‰  \n",
                "âœ… å®Œæ•´ç ”ç©¶ï¼ˆç½‘ç»œ + æ–‡æ¡£åˆ†æï¼‰  \n",
                "âœ… ç ”ç©¶è®¡åˆ’ç”Ÿæˆ  \n",
                "âœ… å¤šæ­¥éª¤ç ”ç©¶æµç¨‹  \n",
                "âœ… ç ”ç©¶æŠ¥å‘Šç”Ÿæˆ  \n",
                "âœ… API é›†æˆæ–¹å¼\n",
                "\n",
                "**ä¸‹ä¸€æ­¥**: å­¦ä¹ ç¬¬ 5 é˜¶æ®µ - Guardrails å®‰å…¨é˜²æŠ¤ï¼ˆ`stage_05_guardrails.ipynb`ï¼‰"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}