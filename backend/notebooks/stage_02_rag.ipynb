{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ç¬¬ 2 é˜¶æ®µï¼šRAG çŸ¥è¯†åº“ + æ–‡æ¡£é—®ç­”\n",
                "\n",
                "æœ¬ Notebook ç”¨äºå­¦ä¹ å’Œè°ƒè¯•ç¬¬ 2 é˜¶æ®µçš„æ ¸å¿ƒåŠŸèƒ½ï¼š\n",
                "- æ–‡æ¡£åŠ è½½ï¼ˆPDFã€Markdownã€HTMLï¼‰\n",
                "- æ–‡æœ¬åˆ†å—ç­–ç•¥\n",
                "- Embedding å‘é‡åŒ–\n",
                "- å‘é‡å­˜å‚¨ä¸ç´¢å¼•ç®¡ç†\n",
                "- æ–‡æ¡£æ£€ç´¢\n",
                "- RAG Agent é—®ç­”\n",
                "\n",
                "**å‚è€ƒæ–‡æ¡£**: `docs/stage_02/`  \n",
                "**å‚è€ƒè„šæœ¬**: `scripts/test_rag_query.py`, `scripts/rag_cli.py`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ç¯å¢ƒå‡†å¤‡"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "backend_dir = Path.cwd()\n",
                "if backend_dir.name == 'notebooks':\n",
                "    backend_dir = backend_dir.parent\n",
                "\n",
                "if str(backend_dir) not in sys.path:\n",
                "    sys.path.insert(0, str(backend_dir))\n",
                "\n",
                "print(f\"âœ… é¡¹ç›®æ ¹ç›®å½•: {backend_dir}\")\n",
                "\n",
                "# å¯¼å…¥å¿…è¦çš„æ¨¡å—\n",
                "from config import settings, get_logger\n",
                "logger = get_logger(__name__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. æ–‡æ¡£åŠ è½½"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 å‡†å¤‡æµ‹è¯•æ–‡æ¡£"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# åˆ›å»ºæµ‹è¯•æ–‡æ¡£ç›®å½•\n",
                "test_docs_dir = backend_dir / \"data\" / \"documents\" / \"test\"\n",
                "test_docs_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# åˆ›å»ºä¸€ä¸ªæµ‹è¯• Markdown æ–‡æ¡£\n",
                "test_md_file = test_docs_dir / \"test_document.md\"\n",
                "test_content = \"\"\"# æœºå™¨å­¦ä¹ åŸºç¡€\n",
                "\n",
                "## ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ\n",
                "\n",
                "æœºå™¨å­¦ä¹ ï¼ˆMachine Learning, MLï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å’Œæ”¹è¿›ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚\n",
                "\n",
                "## æœºå™¨å­¦ä¹ çš„ç±»å‹\n",
                "\n",
                "### 1. ç›‘ç£å­¦ä¹ \n",
                "ç›‘ç£å­¦ä¹ ä½¿ç”¨æ ‡è®°çš„è®­ç»ƒæ•°æ®æ¥å­¦ä¹ è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚å¸¸è§ç®—æ³•åŒ…æ‹¬ï¼š\n",
                "- çº¿æ€§å›å½’\n",
                "- é€»è¾‘å›å½’\n",
                "- å†³ç­–æ ‘\n",
                "- éšæœºæ£®æ—\n",
                "- æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰\n",
                "\n",
                "### 2. æ— ç›‘ç£å­¦ä¹ \n",
                "æ— ç›‘ç£å­¦ä¹ å¤„ç†æœªæ ‡è®°çš„æ•°æ®ï¼Œå¯»æ‰¾æ•°æ®ä¸­çš„æ¨¡å¼å’Œç»“æ„ã€‚å¸¸è§ç®—æ³•åŒ…æ‹¬ï¼š\n",
                "- K-means èšç±»\n",
                "- å±‚æ¬¡èšç±»\n",
                "- ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰\n",
                "- è‡ªç¼–ç å™¨\n",
                "\n",
                "### 3. å¼ºåŒ–å­¦ä¹ \n",
                "å¼ºåŒ–å­¦ä¹ é€šè¿‡ä¸ç¯å¢ƒäº¤äº’æ¥å­¦ä¹ æœ€ä¼˜ç­–ç•¥ï¼Œä»¥æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±ã€‚\n",
                "\n",
                "## æ·±åº¦å­¦ä¹ \n",
                "\n",
                "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å±‚æ¬¡åŒ–è¡¨ç¤ºã€‚\n",
                "\n",
                "### å¸¸è§çš„æ·±åº¦å­¦ä¹ æ¶æ„\n",
                "- å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰- ç”¨äºå›¾åƒå¤„ç†\n",
                "- å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰- ç”¨äºåºåˆ—æ•°æ®\n",
                "- é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰- æ”¹è¿›çš„ RNN\n",
                "- Transformer - ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†\n",
                "\n",
                "## åº”ç”¨åœºæ™¯\n",
                "\n",
                "æœºå™¨å­¦ä¹ åœ¨è®¸å¤šé¢†åŸŸéƒ½æœ‰å¹¿æ³›åº”ç”¨ï¼š\n",
                "- è®¡ç®—æœºè§†è§‰ï¼šå›¾åƒè¯†åˆ«ã€ç›®æ ‡æ£€æµ‹\n",
                "- è‡ªç„¶è¯­è¨€å¤„ç†ï¼šæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æ\n",
                "- æ¨èç³»ç»Ÿï¼šä¸ªæ€§åŒ–æ¨è\n",
                "- è¯­éŸ³è¯†åˆ«ï¼šè¯­éŸ³åŠ©æ‰‹\n",
                "- è‡ªåŠ¨é©¾é©¶ï¼šç¯å¢ƒæ„ŸçŸ¥å’Œå†³ç­–\n",
                "\"\"\"\n",
                "\n",
                "with open(test_md_file, 'w', encoding='utf-8') as f:\n",
                "    f.write(test_content)\n",
                "\n",
                "print(f\"âœ… åˆ›å»ºæµ‹è¯•æ–‡æ¡£: {test_md_file}\")\n",
                "print(f\"   æ–‡æ¡£å¤§å°: {len(test_content)} å­—ç¬¦\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 åŠ è½½æ–‡æ¡£"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rag.loaders import load_documents\n",
                "\n",
                "# åŠ è½½æ–‡æ¡£\n",
                "documents = load_documents(str(test_docs_dir))\n",
                "\n",
                "print(f\"âœ… åŠ è½½æ–‡æ¡£æ•°é‡: {len(documents)}\")\n",
                "print(f\"\\nç¬¬ä¸€ä¸ªæ–‡æ¡£é¢„è§ˆ:\")\n",
                "print(f\"  æ¥æº: {documents[0].metadata.get('source', 'unknown')}\")\n",
                "print(f\"  å†…å®¹é•¿åº¦: {len(documents[0].page_content)} å­—ç¬¦\")\n",
                "print(f\"  å†…å®¹é¢„è§ˆ: {documents[0].page_content[:200]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. æ–‡æœ¬åˆ†å—"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rag.splitters import get_text_splitter\n",
                "\n",
                "# åˆ›å»ºæ–‡æœ¬åˆ†å—å™¨\n",
                "text_splitter = get_text_splitter(\n",
                "    chunk_size=500,  # æ¯å—500å­—ç¬¦\n",
                "    chunk_overlap=50  # é‡å 50å­—ç¬¦\n",
                ")\n",
                "\n",
                "# åˆ†å—\n",
                "chunks = text_splitter.split_documents(documents)\n",
                "\n",
                "print(f\"âœ… åˆ†å—å®Œæˆ\")\n",
                "print(f\"   åŸå§‹æ–‡æ¡£æ•°: {len(documents)}\")\n",
                "print(f\"   åˆ†å—åæ•°é‡: {len(chunks)}\")\n",
                "print(f\"   å—å¤§å°è®¾ç½®: {500} å­—ç¬¦\")\n",
                "print(f\"   é‡å å¤§å°: {50} å­—ç¬¦\")\n",
                "\n",
                "# æŸ¥çœ‹å‰å‡ ä¸ªå—\n",
                "print(\"\\nå‰3ä¸ªæ–‡æœ¬å—:\")\n",
                "for i, chunk in enumerate(chunks[:3], 1):\n",
                "    print(f\"\\n--- å— {i} ---\")\n",
                "    print(f\"é•¿åº¦: {len(chunk.page_content)} å­—ç¬¦\")\n",
                "    print(f\"å†…å®¹: {chunk.page_content[:150]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Embedding å‘é‡åŒ–"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rag.embeddings import get_embeddings\n",
                "\n",
                "# åˆ›å»º Embedding æ¨¡å‹\n",
                "embeddings = get_embeddings()\n",
                "\n",
                "print(f\"âœ… Embedding æ¨¡å‹åˆ›å»ºæˆåŠŸ\")\n",
                "print(f\"   æ¨¡å‹: {settings.embedding_model}\")\n",
                "\n",
                "# æµ‹è¯• embedding\n",
                "test_text = \"æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯\"\n",
                "test_vector = embeddings.embed_query(test_text)\n",
                "\n",
                "print(f\"\\næµ‹è¯•æ–‡æœ¬: {test_text}\")\n",
                "print(f\"å‘é‡ç»´åº¦: {len(test_vector)}\")\n",
                "print(f\"å‘é‡å‰5ä¸ªå€¼: {test_vector[:5]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. å‘é‡å­˜å‚¨ä¸ç´¢å¼•"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.1 åˆ›å»ºå‘é‡å­˜å‚¨"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rag.vector_stores import create_vector_store\n",
                "\n",
                "# åˆ›å»ºå‘é‡å­˜å‚¨\n",
                "print(\"ğŸ”„ åˆ›å»ºå‘é‡å­˜å‚¨...\")\n",
                "vector_store = create_vector_store(chunks, embeddings)\n",
                "\n",
                "print(f\"âœ… å‘é‡å­˜å‚¨åˆ›å»ºæˆåŠŸ\")\n",
                "print(f\"   å­˜å‚¨çš„æ–‡æ¡£å—æ•°: {len(chunks)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 ä¿å­˜ç´¢å¼•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rag.index_manager import IndexManager\n",
                "\n",
                "# åˆ›å»ºç´¢å¼•ç®¡ç†å™¨\n",
                "index_manager = IndexManager()\n",
                "\n",
                "# ä¿å­˜ç´¢å¼•\n",
                "index_name = \"ml_basics\"\n",
                "index_manager.save_index(vector_store, index_name)\n",
                "\n",
                "print(f\"âœ… ç´¢å¼•å·²ä¿å­˜: {index_name}\")\n",
                "print(f\"   ç´¢å¼•è·¯å¾„: {index_manager.get_index_path(index_name)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.3 åŠ è½½ç´¢å¼•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# åŠ è½½å·²ä¿å­˜çš„ç´¢å¼•\n",
                "loaded_vector_store = index_manager.load_index(index_name, embeddings)\n",
                "\n",
                "print(f\"âœ… ç´¢å¼•åŠ è½½æˆåŠŸ: {index_name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.4 åˆ—å‡ºæ‰€æœ‰ç´¢å¼•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# åˆ—å‡ºæ‰€æœ‰å¯ç”¨ç´¢å¼•\n",
                "all_indexes = index_manager.list_indexes()\n",
                "\n",
                "print(f\"ğŸ“š å¯ç”¨ç´¢å¼•åˆ—è¡¨ ({len(all_indexes)} ä¸ª):\")\n",
                "for idx in all_indexes:\n",
                "    print(f\"  - {idx}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. æ–‡æ¡£æ£€ç´¢"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.1 ç›¸ä¼¼åº¦æœç´¢"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢\n",
                "query = \"ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ\"\n",
                "k = 3  # è¿”å›æœ€ç›¸ä¼¼çš„3ä¸ªæ–‡æ¡£\n",
                "\n",
                "print(f\"ğŸ” æŸ¥è¯¢: {query}\")\n",
                "print(f\"   è¿”å›æ•°é‡: {k}\\n\")\n",
                "\n",
                "results = vector_store.similarity_search(query, k=k)\n",
                "\n",
                "print(f\"âœ… æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£:\\n\")\n",
                "for i, doc in enumerate(results, 1):\n",
                "    print(f\"--- æ–‡æ¡£ {i} ---\")\n",
                "    print(f\"å†…å®¹: {doc.page_content[:200]}...\")\n",
                "    print(f\"æ¥æº: {doc.metadata.get('source', 'unknown')}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.2 å¸¦åˆ†æ•°çš„ç›¸ä¼¼åº¦æœç´¢"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# å¸¦ç›¸ä¼¼åº¦åˆ†æ•°çš„æœç´¢\n",
                "results_with_scores = vector_store.similarity_search_with_score(query, k=k)\n",
                "\n",
                "print(f\"ğŸ” æŸ¥è¯¢: {query}\\n\")\n",
                "print(f\"âœ… ç›¸ä¼¼åº¦æœç´¢ç»“æœï¼ˆå¸¦åˆ†æ•°ï¼‰:\\n\")\n",
                "\n",
                "for i, (doc, score) in enumerate(results_with_scores, 1):\n",
                "    print(f\"--- æ–‡æ¡£ {i} (ç›¸ä¼¼åº¦: {score:.4f}) ---\")\n",
                "    print(f\"å†…å®¹: {doc.page_content[:150]}...\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.3 åˆ›å»ºæ£€ç´¢å™¨"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rag.retrievers import create_retriever\n",
                "\n",
                "# åˆ›å»ºæ£€ç´¢å™¨\n",
                "retriever = create_retriever(vector_store, k=4)\n",
                "\n",
                "print(f\"âœ… æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ\")\n",
                "print(f\"   æ£€ç´¢æ•°é‡: 4\")\n",
                "\n",
                "# ä½¿ç”¨æ£€ç´¢å™¨\n",
                "retrieved_docs = retriever.invoke(query)\n",
                "\n",
                "print(f\"\\nğŸ” æ£€ç´¢ç»“æœ: {len(retrieved_docs)} ä¸ªæ–‡æ¡£\")\n",
                "for i, doc in enumerate(retrieved_docs, 1):\n",
                "    print(f\"\\næ–‡æ¡£ {i}:\")\n",
                "    print(f\"  {doc.page_content[:100]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. RAG Agent é—®ç­”"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.1 åˆ›å»º RAG Agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rag.rag_agent import create_rag_agent\n",
                "\n",
                "# åˆ›å»º RAG Agent\n",
                "rag_agent = create_rag_agent(retriever)\n",
                "\n",
                "print(\"âœ… RAG Agent åˆ›å»ºæˆåŠŸ\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2 åŸºç¡€é—®ç­”"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rag.rag_agent import query_rag_agent\n",
                "\n",
                "# æµ‹è¯•é—®é¢˜\n",
                "questions = [\n",
                "    \"ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ\",\n",
                "    \"ç›‘ç£å­¦ä¹ æœ‰å“ªäº›å¸¸è§ç®—æ³•ï¼Ÿ\",\n",
                "    \"æ·±åº¦å­¦ä¹ æœ‰å“ªäº›å¸¸è§æ¶æ„ï¼Ÿ\",\n",
                "    \"æœºå™¨å­¦ä¹ æœ‰å“ªäº›åº”ç”¨åœºæ™¯ï¼Ÿ\"\n",
                "]\n",
                "\n",
                "for i, question in enumerate(questions, 1):\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"é—®é¢˜ {i}: {question}\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    result = query_rag_agent(rag_agent, question)\n",
                "    \n",
                "    print(f\"å›ç­”:\\n{result['answer']}\")\n",
                "    print(f\"\\nå‚è€ƒæ–‡æ¡£æ•°: {len(result.get('source_documents', []))}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.3 æŸ¥çœ‹å¼•ç”¨æ¥æº"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# è¯¦ç»†æŸ¥çœ‹ä¸€ä¸ªé—®é¢˜çš„å›ç­”å’Œæ¥æº\n",
                "question = \"ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿå®ƒæœ‰å“ªäº›åº”ç”¨ï¼Ÿ\"\n",
                "\n",
                "print(f\"ğŸ” é—®é¢˜: {question}\\n\")\n",
                "\n",
                "result = query_rag_agent(rag_agent, question)\n",
                "\n",
                "print(f\"{'='*60}\")\n",
                "print(\"å›ç­”:\")\n",
                "print(f\"{'='*60}\")\n",
                "print(result['answer'])\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(\"å¼•ç”¨æ¥æº:\")\n",
                "print(f\"{'='*60}\")\n",
                "\n",
                "for i, doc in enumerate(result.get('source_documents', []), 1):\n",
                "    print(f\"\\næ¥æº {i}:\")\n",
                "    print(f\"  æ–‡ä»¶: {doc.metadata.get('source', 'unknown')}\")\n",
                "    print(f\"  å†…å®¹: {doc.page_content[:200]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. å®Œæ•´çš„ç´¢å¼•æ„å»ºæµç¨‹"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æ¼”ç¤ºå®Œæ•´çš„ç´¢å¼•æ„å»ºæµç¨‹\n",
                "def build_index_from_directory(docs_path: str, index_name: str):\n",
                "    \"\"\"ä»æ–‡æ¡£ç›®å½•æ„å»ºç´¢å¼•çš„å®Œæ•´æµç¨‹\"\"\"\n",
                "    \n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"æ„å»ºç´¢å¼•: {index_name}\")\n",
                "    print(f\"æ–‡æ¡£è·¯å¾„: {docs_path}\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    # 1. åŠ è½½æ–‡æ¡£\n",
                "    print(\"1ï¸âƒ£  åŠ è½½æ–‡æ¡£...\")\n",
                "    documents = load_documents(docs_path)\n",
                "    print(f\"   âœ… åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£\\n\")\n",
                "    \n",
                "    # 2. æ–‡æœ¬åˆ†å—\n",
                "    print(\"2ï¸âƒ£  æ–‡æœ¬åˆ†å—...\")\n",
                "    splitter = get_text_splitter(\n",
                "        chunk_size=settings.chunk_size,\n",
                "        chunk_overlap=settings.chunk_overlap\n",
                "    )\n",
                "    chunks = splitter.split_documents(documents)\n",
                "    print(f\"   âœ… åˆ†å—ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—\\n\")\n",
                "    \n",
                "    # 3. åˆ›å»º Embedding\n",
                "    print(\"3ï¸âƒ£  åˆ›å»º Embedding...\")\n",
                "    embeddings = get_embeddings()\n",
                "    print(f\"   âœ… ä½¿ç”¨æ¨¡å‹: {settings.embedding_model}\\n\")\n",
                "    \n",
                "    # 4. åˆ›å»ºå‘é‡å­˜å‚¨\n",
                "    print(\"4ï¸âƒ£  åˆ›å»ºå‘é‡å­˜å‚¨...\")\n",
                "    vector_store = create_vector_store(chunks, embeddings)\n",
                "    print(f\"   âœ… å‘é‡å­˜å‚¨åˆ›å»ºå®Œæˆ\\n\")\n",
                "    \n",
                "    # 5. ä¿å­˜ç´¢å¼•\n",
                "    print(\"5ï¸âƒ£  ä¿å­˜ç´¢å¼•...\")\n",
                "    manager = IndexManager()\n",
                "    manager.save_index(vector_store, index_name)\n",
                "    print(f\"   âœ… ç´¢å¼•å·²ä¿å­˜\\n\")\n",
                "    \n",
                "    print(f\"{'='*60}\")\n",
                "    print(f\"âœ… ç´¢å¼•æ„å»ºå®Œæˆ: {index_name}\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    return vector_store\n",
                "\n",
                "# ä½¿ç”¨ç¤ºä¾‹\n",
                "# vector_store = build_index_from_directory(\n",
                "#     str(test_docs_dir),\n",
                "#     \"my_custom_index\"\n",
                "# )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. é«˜çº§åŠŸèƒ½"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 9.1 è‡ªå®šä¹‰åˆ†å—ç­–ç•¥"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æµ‹è¯•ä¸åŒçš„åˆ†å—å‚æ•°\n",
                "chunk_configs = [\n",
                "    {\"chunk_size\": 300, \"chunk_overlap\": 30},\n",
                "    {\"chunk_size\": 500, \"chunk_overlap\": 50},\n",
                "    {\"chunk_size\": 1000, \"chunk_overlap\": 100},\n",
                "]\n",
                "\n",
                "print(\"æµ‹è¯•ä¸åŒçš„åˆ†å—ç­–ç•¥:\\n\")\n",
                "\n",
                "for config in chunk_configs:\n",
                "    splitter = get_text_splitter(**config)\n",
                "    chunks = splitter.split_documents(documents)\n",
                "    \n",
                "    print(f\"å—å¤§å°: {config['chunk_size']}, é‡å : {config['chunk_overlap']}\")\n",
                "    print(f\"  â†’ ç”Ÿæˆ {len(chunks)} ä¸ªæ–‡æœ¬å—\")\n",
                "    print(f\"  â†’ å¹³å‡å—å¤§å°: {sum(len(c.page_content) for c in chunks) / len(chunks):.0f} å­—ç¬¦\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 9.2 å¤šç´¢å¼•ç®¡ç†"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æ¼”ç¤ºå¦‚ä½•ç®¡ç†å¤šä¸ªç´¢å¼•\n",
                "manager = IndexManager()\n",
                "\n",
                "# åˆ—å‡ºæ‰€æœ‰ç´¢å¼•\n",
                "indexes = manager.list_indexes()\n",
                "print(f\"å½“å‰ç´¢å¼•åˆ—è¡¨ ({len(indexes)} ä¸ª):\\n\")\n",
                "\n",
                "for idx_name in indexes:\n",
                "    # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨\n",
                "    exists = manager.index_exists(idx_name)\n",
                "    path = manager.get_index_path(idx_name)\n",
                "    \n",
                "    print(f\"ğŸ“š {idx_name}\")\n",
                "    print(f\"   å­˜åœ¨: {exists}\")\n",
                "    print(f\"   è·¯å¾„: {path}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 9.3 åˆ é™¤ç´¢å¼•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# åˆ é™¤æµ‹è¯•ç´¢å¼•ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰\n",
                "# manager.delete_index(\"ml_basics\")\n",
                "# print(\"âœ… ç´¢å¼•å·²åˆ é™¤\")\n",
                "\n",
                "print(\"âš ï¸  å–æ¶ˆæ³¨é‡Šä¸Šé¢çš„ä»£ç ä»¥åˆ é™¤ç´¢å¼•\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. æ€»ç»“\n",
                "\n",
                "é€šè¿‡æœ¬ Notebookï¼Œä½ å·²ç»å­¦ä¹ äº†ï¼š\n",
                "\n",
                "âœ… æ–‡æ¡£åŠ è½½ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰  \n",
                "âœ… æ–‡æœ¬åˆ†å—ç­–ç•¥ä¸å‚æ•°è°ƒä¼˜  \n",
                "âœ… Embedding å‘é‡åŒ–  \n",
                "âœ… å‘é‡å­˜å‚¨çš„åˆ›å»ºä¸ç®¡ç†  \n",
                "âœ… ç´¢å¼•çš„ä¿å­˜ã€åŠ è½½å’Œåˆ é™¤  \n",
                "âœ… æ–‡æ¡£æ£€ç´¢ï¼ˆç›¸ä¼¼åº¦æœç´¢ï¼‰  \n",
                "âœ… RAG Agent çš„åˆ›å»ºä¸é—®ç­”  \n",
                "âœ… å¼•ç”¨æ¥æºçš„è¿½è¸ª  \n",
                "âœ… å¤šç´¢å¼•ç®¡ç†\n",
                "\n",
                "**ä¸‹ä¸€æ­¥**: å­¦ä¹ ç¬¬ 3 é˜¶æ®µ - LangGraph å·¥ä½œæµï¼ˆ`stage_03_workflow.ipynb`ï¼‰"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}