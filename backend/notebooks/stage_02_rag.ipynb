{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ç¬¬ 2 é˜¶æ®µï¼šRAG çŸ¥è¯†åº“ + æ–‡æ¡£é—®ç­”\n",
                "\n",
                "æœ¬ Notebook ç”¨äºå­¦ä¹ å’Œè°ƒè¯•ç¬¬ 2 é˜¶æ®µçš„æ ¸å¿ƒåŠŸèƒ½ï¼š\n",
                "- æ–‡æ¡£åŠ è½½ï¼ˆPDFã€Markdownã€HTMLï¼‰\n",
                "- æ–‡æœ¬åˆ†å—ç­–ç•¥\n",
                "- Embedding å‘é‡åŒ–\n",
                "- å‘é‡å­˜å‚¨ä¸ç´¢å¼•ç®¡ç†\n",
                "- æ–‡æ¡£æ£€ç´¢\n",
                "- RAG Agent é—®ç­”\n",
                "\n",
                "**å‚è€ƒæ–‡æ¡£**: `docs/stage_02/`  \n",
                "**å‚è€ƒè„šæœ¬**: `scripts/test_rag_query.py`, `scripts/rag_cli.py`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ç¯å¢ƒå‡†å¤‡"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2025-12-04 20:09:08.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mconfig.logging\u001b[0m:\u001b[36msetup_logging\u001b[0m:\u001b[36m83\u001b[0m | \u001b[1mğŸ“ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ - çº§åˆ«: INFO, æ–‡ä»¶: logs/app.log\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… é¡¹ç›®æ ¹ç›®å½•: /Users/yuan/dev/ai-projects/lc-studylab/backend\n"
                    ]
                }
            ],
            "source": [
                "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "backend_dir = Path.cwd()\n",
                "if backend_dir.name == 'notebooks':\n",
                "    backend_dir = backend_dir.parent\n",
                "\n",
                "if str(backend_dir) not in sys.path:\n",
                "    sys.path.insert(0, str(backend_dir))\n",
                "\n",
                "print(f\"âœ… é¡¹ç›®æ ¹ç›®å½•: {backend_dir}\")\n",
                "\n",
                "# å¯¼å…¥å¿…è¦çš„æ¨¡å—\n",
                "from config import settings, get_logger\n",
                "logger = get_logger(__name__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. æ–‡æ¡£åŠ è½½"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 å‡†å¤‡æµ‹è¯•æ–‡æ¡£"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… åˆ›å»ºæµ‹è¯•æ–‡æ¡£: /Users/yuan/dev/ai-projects/lc-studylab/backend/data/documents/test/test_document.md\n",
                        "   æ–‡æ¡£å¤§å°: 580 å­—ç¬¦\n"
                    ]
                }
            ],
            "source": [
                "# åˆ›å»ºæµ‹è¯•æ–‡æ¡£ç›®å½•\n",
                "test_docs_dir = backend_dir / \"data\" / \"documents\" / \"test\"\n",
                "test_docs_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# åˆ›å»ºä¸€ä¸ªæµ‹è¯• Markdown æ–‡æ¡£\n",
                "test_md_file = test_docs_dir / \"test_document.md\"\n",
                "test_content = \"\"\"# æœºå™¨å­¦ä¹ åŸºç¡€\n",
                "\n",
                "## ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ\n",
                "\n",
                "æœºå™¨å­¦ä¹ ï¼ˆMachine Learning, MLï¼‰æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å’Œæ”¹è¿›ï¼Œè€Œæ— éœ€æ˜ç¡®ç¼–ç¨‹ã€‚\n",
                "\n",
                "## æœºå™¨å­¦ä¹ çš„ç±»å‹\n",
                "\n",
                "### 1. ç›‘ç£å­¦ä¹ \n",
                "ç›‘ç£å­¦ä¹ ä½¿ç”¨æ ‡è®°çš„è®­ç»ƒæ•°æ®æ¥å­¦ä¹ è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚å¸¸è§ç®—æ³•åŒ…æ‹¬ï¼š\n",
                "- çº¿æ€§å›å½’\n",
                "- é€»è¾‘å›å½’\n",
                "- å†³ç­–æ ‘\n",
                "- éšæœºæ£®æ—\n",
                "- æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰\n",
                "\n",
                "### 2. æ— ç›‘ç£å­¦ä¹ \n",
                "æ— ç›‘ç£å­¦ä¹ å¤„ç†æœªæ ‡è®°çš„æ•°æ®ï¼Œå¯»æ‰¾æ•°æ®ä¸­çš„æ¨¡å¼å’Œç»“æ„ã€‚å¸¸è§ç®—æ³•åŒ…æ‹¬ï¼š\n",
                "- K-means èšç±»\n",
                "- å±‚æ¬¡èšç±»\n",
                "- ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰\n",
                "- è‡ªç¼–ç å™¨\n",
                "\n",
                "### 3. å¼ºåŒ–å­¦ä¹ \n",
                "å¼ºåŒ–å­¦ä¹ é€šè¿‡ä¸ç¯å¢ƒäº¤äº’æ¥å­¦ä¹ æœ€ä¼˜ç­–ç•¥ï¼Œä»¥æœ€å¤§åŒ–ç´¯ç§¯å¥–åŠ±ã€‚\n",
                "\n",
                "## æ·±åº¦å­¦ä¹ \n",
                "\n",
                "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„å±‚æ¬¡åŒ–è¡¨ç¤ºã€‚\n",
                "\n",
                "### å¸¸è§çš„æ·±åº¦å­¦ä¹ æ¶æ„\n",
                "- å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰- ç”¨äºå›¾åƒå¤„ç†\n",
                "- å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰- ç”¨äºåºåˆ—æ•°æ®\n",
                "- é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰- æ”¹è¿›çš„ RNN\n",
                "- Transformer - ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†\n",
                "\n",
                "## åº”ç”¨åœºæ™¯\n",
                "\n",
                "æœºå™¨å­¦ä¹ åœ¨è®¸å¤šé¢†åŸŸéƒ½æœ‰å¹¿æ³›åº”ç”¨ï¼š\n",
                "- è®¡ç®—æœºè§†è§‰ï¼šå›¾åƒè¯†åˆ«ã€ç›®æ ‡æ£€æµ‹\n",
                "- è‡ªç„¶è¯­è¨€å¤„ç†ï¼šæœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æ\n",
                "- æ¨èç³»ç»Ÿï¼šä¸ªæ€§åŒ–æ¨è\n",
                "- è¯­éŸ³è¯†åˆ«ï¼šè¯­éŸ³åŠ©æ‰‹\n",
                "- è‡ªåŠ¨é©¾é©¶ï¼šç¯å¢ƒæ„ŸçŸ¥å’Œå†³ç­–\n",
                "\"\"\"\n",
                "\n",
                "with open(test_md_file, 'w', encoding='utf-8') as f:\n",
                "    f.write(test_content)\n",
                "\n",
                "print(f\"âœ… åˆ›å»ºæµ‹è¯•æ–‡æ¡£: {test_md_file}\")\n",
                "print(f\"   æ–‡æ¡£å¤§å°: {len(test_content)} å­—ç¬¦\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 åŠ è½½æ–‡æ¡£"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2025-12-04 20:09:16.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m228\u001b[0m | \u001b[1mğŸ“ å¼€å§‹åŠ è½½ç›®å½•: /Users/yuan/dev/ai-projects/lc-studylab/backend/data/documents/test\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:16.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m229\u001b[0m | \u001b[1m   åŒ¹é…æ¨¡å¼: **/*\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:16.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m258\u001b[0m | \u001b[1m   æ‰¾åˆ° 6 ä¸ªæ–‡ä»¶\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:16.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m268\u001b[0m | \u001b[1m   [1/6] åŠ è½½: python_basics.txt\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:16.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_document\u001b[0m:\u001b[36m157\u001b[0m | \u001b[1mğŸ“„ åŠ è½½æ–‡æ¡£: /Users/yuan/dev/ai-projects/lc-studylab/backend/data/documents/test/python_basics.txt\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:16.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_document\u001b[0m:\u001b[36m171\u001b[0m | \u001b[1mâœ… æˆåŠŸåŠ è½½ 1 ä¸ªæ–‡æ¡£å—\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:16.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m268\u001b[0m | \u001b[1m   [2/6] åŠ è½½: machine_learning.md\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:16.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_document\u001b[0m:\u001b[36m157\u001b[0m | \u001b[1mğŸ“„ åŠ è½½æ–‡æ¡£: /Users/yuan/dev/ai-projects/lc-studylab/backend/data/documents/test/machine_learning.md\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_document\u001b[0m:\u001b[36m171\u001b[0m | \u001b[1mâœ… æˆåŠŸåŠ è½½ 1 ä¸ªæ–‡æ¡£å—\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m268\u001b[0m | \u001b[1m   [3/6] åŠ è½½: neural_networks.md\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.454\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_document\u001b[0m:\u001b[36m157\u001b[0m | \u001b[1mğŸ“„ åŠ è½½æ–‡æ¡£: /Users/yuan/dev/ai-projects/lc-studylab/backend/data/documents/test/neural_networks.md\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_document\u001b[0m:\u001b[36m171\u001b[0m | \u001b[1mâœ… æˆåŠŸåŠ è½½ 1 ä¸ªæ–‡æ¡£å—\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m268\u001b[0m | \u001b[1m   [4/6] åŠ è½½: test_document.md\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_document\u001b[0m:\u001b[36m157\u001b[0m | \u001b[1mğŸ“„ åŠ è½½æ–‡æ¡£: /Users/yuan/dev/ai-projects/lc-studylab/backend/data/documents/test/test_document.md\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_document\u001b[0m:\u001b[36m171\u001b[0m | \u001b[1mâœ… æˆåŠŸåŠ è½½ 1 ä¸ªæ–‡æ¡£å—\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m268\u001b[0m | \u001b[1m   [5/6] åŠ è½½: é•¿æ±Ÿèµ‹.md\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_document\u001b[0m:\u001b[36m157\u001b[0m | \u001b[1mğŸ“„ åŠ è½½æ–‡æ¡£: /Users/yuan/dev/ai-projects/lc-studylab/backend/data/documents/test/é•¿æ±Ÿèµ‹.md\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_document\u001b[0m:\u001b[36m171\u001b[0m | \u001b[1mâœ… æˆåŠŸåŠ è½½ 1 ä¸ªæ–‡æ¡£å—\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m268\u001b[0m | \u001b[1m   [6/6] åŠ è½½: deep_learning.md\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_document\u001b[0m:\u001b[36m157\u001b[0m | \u001b[1mğŸ“„ åŠ è½½æ–‡æ¡£: /Users/yuan/dev/ai-projects/lc-studylab/backend/data/documents/test/deep_learning.md\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_document\u001b[0m:\u001b[36m171\u001b[0m | \u001b[1mâœ… æˆåŠŸåŠ è½½ 1 ä¸ªæ–‡æ¡£å—\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m279\u001b[0m | \u001b[1mâœ… ç›®å½•åŠ è½½å®Œæˆ:\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m280\u001b[0m | \u001b[1m   æˆåŠŸ: 6 ä¸ªæ–‡ä»¶\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m281\u001b[0m | \u001b[1m   å¤±è´¥: 0 ä¸ªæ–‡ä»¶\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:20.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.loaders\u001b[0m:\u001b[36mload_directory\u001b[0m:\u001b[36m282\u001b[0m | \u001b[1m   æ€»è®¡: 6 ä¸ªæ–‡æ¡£å—\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… åŠ è½½æ–‡æ¡£æ•°é‡: 6\n",
                        "\n",
                        "ç¬¬ä¸€ä¸ªæ–‡æ¡£é¢„è§ˆ:\n",
                        "  æ¥æº: /Users/yuan/dev/ai-projects/lc-studylab/backend/data/documents/test/python_basics.txt\n",
                        "  å†…å®¹é•¿åº¦: 1604 å­—ç¬¦\n",
                        "  å†…å®¹é¢„è§ˆ: Python ç¼–ç¨‹åŸºç¡€\n",
                        "\n",
                        "Python æ˜¯ä¸€ç§é«˜çº§ã€è§£é‡Šå‹ã€é€šç”¨çš„ç¼–ç¨‹è¯­è¨€ã€‚å®ƒä»¥ç®€æ´æ˜“è¯»çš„è¯­æ³•è€Œé—»åï¼Œæ˜¯åˆå­¦è€…å’Œä¸“ä¸šå¼€å‘è€…çš„ç†æƒ³é€‰æ‹©ã€‚\n",
                        "\n",
                        "Python çš„ç‰¹ç‚¹ï¼š\n",
                        "\n",
                        "1. ç®€å•æ˜“å­¦\n",
                        "   - æ¸…æ™°çš„è¯­æ³•\n",
                        "   - æ¥è¿‘è‡ªç„¶è¯­è¨€\n",
                        "   - ç¼©è¿›è¡¨ç¤ºä»£ç å—\n",
                        "\n",
                        "2. åŠŸèƒ½å¼ºå¤§\n",
                        "   - ä¸°å¯Œçš„æ ‡å‡†åº“\n",
                        "   - å¤§é‡ç¬¬ä¸‰æ–¹åŒ…\n",
                        "   - æ”¯æŒå¤šç§ç¼–ç¨‹èŒƒå¼\n",
                        "\n",
                        "3. è·¨å¹³å°\n",
                        "   - Windowsã€macOSã€...\n"
                    ]
                }
            ],
            "source": [
                "from rag.loaders import load_directory\n",
                "\n",
                "# åŠ è½½æ–‡æ¡£\n",
                "documents = load_directory(str(test_docs_dir))\n",
                "\n",
                "print(f\"âœ… åŠ è½½æ–‡æ¡£æ•°é‡: {len(documents)}\")\n",
                "print(f\"\\nç¬¬ä¸€ä¸ªæ–‡æ¡£é¢„è§ˆ:\")\n",
                "print(f\"  æ¥æº: {documents[0].metadata.get('source', 'unknown')}\")\n",
                "print(f\"  å†…å®¹é•¿åº¦: {len(documents[0].page_content)} å­—ç¬¦\")\n",
                "print(f\"  å†…å®¹é¢„è§ˆ: {documents[0].page_content[:200]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. æ–‡æœ¬åˆ†å—"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… åˆ†å—å®Œæˆ\n",
                        "   åŸå§‹æ–‡æ¡£æ•°: 6\n",
                        "   åˆ†å—åæ•°é‡: 18\n",
                        "   å—å¤§å°è®¾ç½®: 500 å­—ç¬¦\n",
                        "   é‡å å¤§å°: 50 å­—ç¬¦\n",
                        "\n",
                        "å‰3ä¸ªæ–‡æœ¬å—:\n",
                        "\n",
                        "--- å— 1 ---\n",
                        "é•¿åº¦: 432 å­—ç¬¦\n",
                        "å†…å®¹: Python ç¼–ç¨‹åŸºç¡€\n",
                        "\n",
                        "Python æ˜¯ä¸€ç§é«˜çº§ã€è§£é‡Šå‹ã€é€šç”¨çš„ç¼–ç¨‹è¯­è¨€ã€‚å®ƒä»¥ç®€æ´æ˜“è¯»çš„è¯­æ³•è€Œé—»åï¼Œæ˜¯åˆå­¦è€…å’Œä¸“ä¸šå¼€å‘è€…çš„ç†æƒ³é€‰æ‹©ã€‚\n",
                        "\n",
                        "Python çš„ç‰¹ç‚¹ï¼š\n",
                        "\n",
                        "1. ç®€å•æ˜“å­¦\n",
                        "   - æ¸…æ™°çš„è¯­æ³•\n",
                        "   - æ¥è¿‘è‡ªç„¶è¯­è¨€\n",
                        "   - ç¼©è¿›è¡¨ç¤ºä»£ç å—\n",
                        "\n",
                        "2. åŠŸèƒ½å¼ºå¤§\n",
                        "   - ä¸°å¯Œçš„æ ‡å‡†åº“\n",
                        "   ...\n",
                        "\n",
                        "--- å— 2 ---\n",
                        "é•¿åº¦: 485 å­—ç¬¦\n",
                        "å†…å®¹: åŸºæœ¬è¯­æ³•ï¼š\n",
                        "\n",
                        "å˜é‡å’Œæ•°æ®ç±»å‹ï¼š\n",
                        "- æ•´æ•°ï¼šx = 10\n",
                        "- æµ®ç‚¹æ•°ï¼šy = 3.14\n",
                        "- å­—ç¬¦ä¸²ï¼šname = \"Python\"\n",
                        "- å¸ƒå°”å€¼ï¼šis_true = True\n",
                        "- åˆ—è¡¨ï¼šnumbers = [1, 2, 3, 4, 5]\n",
                        "- å­—å…¸ï¼šperson = {\"name\": \"Alice\", \"...\n",
                        "\n",
                        "--- å— 3 ---\n",
                        "é•¿åº¦: 428 å­—ç¬¦\n",
                        "å†…å®¹: å¼‚å¸¸å¤„ç†ï¼š\n",
                        "try:\n",
                        "    result = 10 / 0\n",
                        "except ZeroDivisionError:\n",
                        "    print(\"Cannot divide by zero!\")\n",
                        "finally:\n",
                        "    print(\"Cleanup code\")\n",
                        "\n",
                        "æ–‡ä»¶æ“ä½œï¼š\n",
                        "with open(\"file...\n"
                    ]
                }
            ],
            "source": [
                "from rag.splitters import get_text_splitter\n",
                "\n",
                "# åˆ›å»ºæ–‡æœ¬åˆ†å—å™¨\n",
                "text_splitter = get_text_splitter(\n",
                "    chunk_size=500,  # æ¯å—500å­—ç¬¦\n",
                "    chunk_overlap=50  # é‡å 50å­—ç¬¦\n",
                ")\n",
                "\n",
                "# åˆ†å—\n",
                "chunks = text_splitter.split_documents(documents)\n",
                "\n",
                "print(f\"âœ… åˆ†å—å®Œæˆ\")\n",
                "print(f\"   åŸå§‹æ–‡æ¡£æ•°: {len(documents)}\")\n",
                "print(f\"   åˆ†å—åæ•°é‡: {len(chunks)}\")\n",
                "print(f\"   å—å¤§å°è®¾ç½®: {500} å­—ç¬¦\")\n",
                "print(f\"   é‡å å¤§å°: {50} å­—ç¬¦\")\n",
                "\n",
                "# æŸ¥çœ‹å‰å‡ ä¸ªå—\n",
                "print(\"\\nå‰3ä¸ªæ–‡æœ¬å—:\")\n",
                "for i, chunk in enumerate(chunks[:3], 1):\n",
                "    print(f\"\\n--- å— {i} ---\")\n",
                "    print(f\"é•¿åº¦: {len(chunk.page_content)} å­—ç¬¦\")\n",
                "    print(f\"å†…å®¹: {chunk.page_content[:150]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Embedding å‘é‡åŒ–"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2025-12-04 20:09:31.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.embeddings\u001b[0m:\u001b[36mget_embeddings\u001b[0m:\u001b[36m162\u001b[0m | \u001b[1mğŸ”¢ åˆ›å»º Embedding æ¨¡å‹: netease-youdao/bce-embedding-base_v1\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Embedding æ¨¡å‹åˆ›å»ºæˆåŠŸ\n",
                        "   æ¨¡å‹: text-embedding-3-small\n",
                        "\n",
                        "æµ‹è¯•æ–‡æœ¬: æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯\n",
                        "å‘é‡ç»´åº¦: 768\n",
                        "å‘é‡å‰5ä¸ªå€¼: [0.012994864024221897, 0.02401718683540821, -0.031249837949872017, 0.028882788494229317, -0.01769309863448143]\n"
                    ]
                }
            ],
            "source": [
                "from rag.embeddings import get_embeddings\n",
                "\n",
                "# åˆ›å»º Embedding æ¨¡å‹\n",
                "embeddings = get_embeddings(model=\"netease-youdao/bce-embedding-base_v1\")\n",
                "\n",
                "print(f\"âœ… Embedding æ¨¡å‹åˆ›å»ºæˆåŠŸ\")\n",
                "print(f\"   æ¨¡å‹: {settings.embedding_model}\")\n",
                "\n",
                "# æµ‹è¯• embedding\n",
                "test_text = \"æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯\"\n",
                "test_vector = embeddings.embed_query(test_text)\n",
                "\n",
                "print(f\"\\næµ‹è¯•æ–‡æœ¬: {test_text}\")\n",
                "print(f\"å‘é‡ç»´åº¦: {len(test_vector)}\")\n",
                "print(f\"å‘é‡å‰5ä¸ªå€¼: {test_vector[:5]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. å‘é‡å­˜å‚¨ä¸ç´¢å¼•"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.1 åˆ›å»ºå‘é‡å­˜å‚¨"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2025-12-04 20:09:36.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.vector_stores\u001b[0m:\u001b[36mcreate_vector_store\u001b[0m:\u001b[36m75\u001b[0m | \u001b[1mğŸ—„ï¸  åˆ›å»ºå‘é‡å­˜å‚¨: type=faiss, documents=18\u001b[0m\n",
                        "\u001b[32m2025-12-04 20:09:37.001\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mrag.embeddings\u001b[0m:\u001b[36m_truncate_text\u001b[0m:\u001b[36m79\u001b[0m | \u001b[33m\u001b[1mæ–‡æœ¬è¿‡é•¿ (746 tokens)ï¼Œæˆªæ–­åˆ° 512 tokens\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸ”„ åˆ›å»ºå‘é‡å­˜å‚¨...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2025-12-04 20:09:37.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.vector_stores\u001b[0m:\u001b[36mcreate_vector_store\u001b[0m:\u001b[36m89\u001b[0m | \u001b[1mâœ… FAISS å‘é‡åº“åˆ›å»ºæˆåŠŸ\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… å‘é‡å­˜å‚¨åˆ›å»ºæˆåŠŸ\n",
                        "   å­˜å‚¨çš„æ–‡æ¡£å—æ•°: 18\n"
                    ]
                }
            ],
            "source": [
                "from rag.vector_stores import create_vector_store\n",
                "\n",
                "# åˆ›å»ºå‘é‡å­˜å‚¨\n",
                "print(\"ğŸ”„ åˆ›å»ºå‘é‡å­˜å‚¨...\")\n",
                "vector_store = create_vector_store(chunks, embeddings)\n",
                "\n",
                "print(f\"âœ… å‘é‡å­˜å‚¨åˆ›å»ºæˆåŠŸ\")\n",
                "print(f\"   å­˜å‚¨çš„æ–‡æ¡£å—æ•°: {len(chunks)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 ä¿å­˜ç´¢å¼•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2025-12-04 20:13:42.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag.index_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m79\u001b[0m | \u001b[1mğŸ“ ç´¢å¼•ç®¡ç†å™¨åˆå§‹åŒ–: data/indexes\u001b[0m\n"
                    ]
                },
                {
                    "ename": "ValueError",
                    "evalue": "ç´¢å¼•å·²å­˜åœ¨: ml_basicsã€‚ä½¿ç”¨ overwrite=True æ¥è¦†ç›–ã€‚",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ä¿å­˜ç´¢å¼•\u001b[39;00m\n\u001b[32m      7\u001b[39m index_name = \u001b[33m\"\u001b[39m\u001b[33mml_basics\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mindex_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… ç´¢å¼•å·²ä¿å­˜: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ç´¢å¼•è·¯å¾„: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_manager.get_index_info(index_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/dev/ai-projects/lc-studylab/backend/rag/index_manager.py:158\u001b[39m, in \u001b[36mIndexManager.create_index\u001b[39m\u001b[34m(self, name, documents, embeddings, description, store_type, overwrite, **kwargs)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;66;03m# æ£€æŸ¥ç´¢å¼•æ˜¯å¦å·²å­˜åœ¨\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index_path.exists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    159\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mç´¢å¼•å·²å­˜åœ¨: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mã€‚ä½¿ç”¨ overwrite=True æ¥è¦†ç›–ã€‚\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m     )\n\u001b[32m    162\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ”¨ åˆ›å»ºç´¢å¼•: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    163\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   æ–‡æ¡£æ•°é‡: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[31mValueError\u001b[39m: ç´¢å¼•å·²å­˜åœ¨: ml_basicsã€‚ä½¿ç”¨ overwrite=True æ¥è¦†ç›–ã€‚"
                    ]
                }
            ],
            "source": [
                "from rag.index_manager import IndexManager\n",
                "\n",
                "# åˆ›å»ºç´¢å¼•ç®¡ç†å™¨\n",
                "index_manager = IndexManager()\n",
                "\n",
                "# ä¿å­˜ç´¢å¼•\n",
                "index_name = \"ml_basics\"\n",
                "index_manager.create_index(index_name,embeddings=embeddings,documents=chunks,overwrite=True)\n",
                "\n",
                "print(f\"âœ… ç´¢å¼•å·²ä¿å­˜: {index_name}\")\n",
                "print(f\"   ç´¢å¼•è·¯å¾„: {index_manager.get_index_info(index_name)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.3 åŠ è½½ç´¢å¼•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# åŠ è½½å·²ä¿å­˜çš„ç´¢å¼•\n",
                "loaded_vector_store = index_manager.load_index(index_name, embeddings)\n",
                "\n",
                "print(f\"âœ… ç´¢å¼•åŠ è½½æˆåŠŸ: {index_name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.4 åˆ—å‡ºæ‰€æœ‰ç´¢å¼•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# åˆ—å‡ºæ‰€æœ‰å¯ç”¨ç´¢å¼•\n",
                "all_indexes = index_manager.list_indexes()\n",
                "\n",
                "print(f\"ğŸ“š å¯ç”¨ç´¢å¼•åˆ—è¡¨ ({len(all_indexes)} ä¸ª):\")\n",
                "for idx in all_indexes:\n",
                "    print(f\"  - {idx}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. æ–‡æ¡£æ£€ç´¢"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.1 ç›¸ä¼¼åº¦æœç´¢"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢\n",
                "query = \"ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ\"\n",
                "k = 3  # è¿”å›æœ€ç›¸ä¼¼çš„3ä¸ªæ–‡æ¡£\n",
                "\n",
                "print(f\"ğŸ” æŸ¥è¯¢: {query}\")\n",
                "print(f\"   è¿”å›æ•°é‡: {k}\\n\")\n",
                "\n",
                "results = vector_store.similarity_search(query, k=k)\n",
                "\n",
                "print(f\"âœ… æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£:\\n\")\n",
                "for i, doc in enumerate(results, 1):\n",
                "    print(f\"--- æ–‡æ¡£ {i} ---\")\n",
                "    print(f\"å†…å®¹: {doc.page_content[:200]}...\")\n",
                "    print(f\"æ¥æº: {doc.metadata.get('source', 'unknown')}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.2 å¸¦åˆ†æ•°çš„ç›¸ä¼¼åº¦æœç´¢"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# å¸¦ç›¸ä¼¼åº¦åˆ†æ•°çš„æœç´¢\n",
                "results_with_scores = vector_store.similarity_search_with_score(query, k=k)\n",
                "\n",
                "print(f\"ğŸ” æŸ¥è¯¢: {query}\\n\")\n",
                "print(f\"âœ… ç›¸ä¼¼åº¦æœç´¢ç»“æœï¼ˆå¸¦åˆ†æ•°ï¼‰:\\n\")\n",
                "\n",
                "for i, (doc, score) in enumerate(results_with_scores, 1):\n",
                "    print(f\"--- æ–‡æ¡£ {i} (ç›¸ä¼¼åº¦: {score:.4f}) ---\")\n",
                "    print(f\"å†…å®¹: {doc.page_content[:150]}...\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.3 åˆ›å»ºæ£€ç´¢å™¨"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rag.retrievers import create_retriever\n",
                "\n",
                "# åˆ›å»ºæ£€ç´¢å™¨\n",
                "retriever = create_retriever(vector_store, k=4)\n",
                "\n",
                "print(f\"âœ… æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ\")\n",
                "print(f\"   æ£€ç´¢æ•°é‡: 4\")\n",
                "\n",
                "# ä½¿ç”¨æ£€ç´¢å™¨\n",
                "retrieved_docs = retriever.invoke(query)\n",
                "\n",
                "print(f\"\\nğŸ” æ£€ç´¢ç»“æœ: {len(retrieved_docs)} ä¸ªæ–‡æ¡£\")\n",
                "for i, doc in enumerate(retrieved_docs, 1):\n",
                "    print(f\"\\næ–‡æ¡£ {i}:\")\n",
                "    print(f\"  {doc.page_content[:100]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. RAG Agent é—®ç­”"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.1 åˆ›å»º RAG Agent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rag.rag_agent import create_rag_agent\n",
                "\n",
                "# åˆ›å»º RAG Agent\n",
                "rag_agent = create_rag_agent(retriever)\n",
                "\n",
                "print(\"âœ… RAG Agent åˆ›å»ºæˆåŠŸ\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2 åŸºç¡€é—®ç­”"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rag.rag_agent import query_rag_agent\n",
                "\n",
                "# æµ‹è¯•é—®é¢˜\n",
                "questions = [\n",
                "    \"ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ\",\n",
                "    \"ç›‘ç£å­¦ä¹ æœ‰å“ªäº›å¸¸è§ç®—æ³•ï¼Ÿ\",\n",
                "    \"æ·±åº¦å­¦ä¹ æœ‰å“ªäº›å¸¸è§æ¶æ„ï¼Ÿ\",\n",
                "    \"æœºå™¨å­¦ä¹ æœ‰å“ªäº›åº”ç”¨åœºæ™¯ï¼Ÿ\"\n",
                "]\n",
                "\n",
                "for i, question in enumerate(questions, 1):\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"é—®é¢˜ {i}: {question}\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    result = query_rag_agent(rag_agent, question)\n",
                "    \n",
                "    print(f\"å›ç­”:\\n{result['answer']}\")\n",
                "    print(f\"\\nå‚è€ƒæ–‡æ¡£æ•°: {len(result.get('source_documents', []))}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.3 æŸ¥çœ‹å¼•ç”¨æ¥æº"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# è¯¦ç»†æŸ¥çœ‹ä¸€ä¸ªé—®é¢˜çš„å›ç­”å’Œæ¥æº\n",
                "question = \"ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿå®ƒæœ‰å“ªäº›åº”ç”¨ï¼Ÿ\"\n",
                "\n",
                "print(f\"ğŸ” é—®é¢˜: {question}\\n\")\n",
                "\n",
                "result = query_rag_agent(rag_agent, question)\n",
                "\n",
                "print(f\"{'='*60}\")\n",
                "print(\"å›ç­”:\")\n",
                "print(f\"{'='*60}\")\n",
                "print(result['answer'])\n",
                "\n",
                "print(f\"\\n{'='*60}\")\n",
                "print(\"å¼•ç”¨æ¥æº:\")\n",
                "print(f\"{'='*60}\")\n",
                "\n",
                "for i, doc in enumerate(result.get('source_documents', []), 1):\n",
                "    print(f\"\\næ¥æº {i}:\")\n",
                "    print(f\"  æ–‡ä»¶: {doc.metadata.get('source', 'unknown')}\")\n",
                "    print(f\"  å†…å®¹: {doc.page_content[:200]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. å®Œæ•´çš„ç´¢å¼•æ„å»ºæµç¨‹"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æ¼”ç¤ºå®Œæ•´çš„ç´¢å¼•æ„å»ºæµç¨‹\n",
                "def build_index_from_directory(docs_path: str, index_name: str):\n",
                "    \"\"\"ä»æ–‡æ¡£ç›®å½•æ„å»ºç´¢å¼•çš„å®Œæ•´æµç¨‹\"\"\"\n",
                "    \n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"æ„å»ºç´¢å¼•: {index_name}\")\n",
                "    print(f\"æ–‡æ¡£è·¯å¾„: {docs_path}\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    # 1. åŠ è½½æ–‡æ¡£\n",
                "    print(\"1ï¸âƒ£  åŠ è½½æ–‡æ¡£...\")\n",
                "    documents = load_documents(docs_path)\n",
                "    print(f\"   âœ… åŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£\\n\")\n",
                "    \n",
                "    # 2. æ–‡æœ¬åˆ†å—\n",
                "    print(\"2ï¸âƒ£  æ–‡æœ¬åˆ†å—...\")\n",
                "    splitter = get_text_splitter(\n",
                "        chunk_size=settings.chunk_size,\n",
                "        chunk_overlap=settings.chunk_overlap\n",
                "    )\n",
                "    chunks = splitter.split_documents(documents)\n",
                "    print(f\"   âœ… åˆ†å—ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—\\n\")\n",
                "    \n",
                "    # 3. åˆ›å»º Embedding\n",
                "    print(\"3ï¸âƒ£  åˆ›å»º Embedding...\")\n",
                "    embeddings = get_embeddings()\n",
                "    print(f\"   âœ… ä½¿ç”¨æ¨¡å‹: {settings.embedding_model}\\n\")\n",
                "    \n",
                "    # 4. åˆ›å»ºå‘é‡å­˜å‚¨\n",
                "    print(\"4ï¸âƒ£  åˆ›å»ºå‘é‡å­˜å‚¨...\")\n",
                "    vector_store = create_vector_store(chunks, embeddings)\n",
                "    print(f\"   âœ… å‘é‡å­˜å‚¨åˆ›å»ºå®Œæˆ\\n\")\n",
                "    \n",
                "    # 5. ä¿å­˜ç´¢å¼•\n",
                "    print(\"5ï¸âƒ£  ä¿å­˜ç´¢å¼•...\")\n",
                "    manager = IndexManager()\n",
                "    manager.save_index(vector_store, index_name)\n",
                "    print(f\"   âœ… ç´¢å¼•å·²ä¿å­˜\\n\")\n",
                "    \n",
                "    print(f\"{'='*60}\")\n",
                "    print(f\"âœ… ç´¢å¼•æ„å»ºå®Œæˆ: {index_name}\")\n",
                "    print(f\"{'='*60}\\n\")\n",
                "    \n",
                "    return vector_store\n",
                "\n",
                "# ä½¿ç”¨ç¤ºä¾‹\n",
                "# vector_store = build_index_from_directory(\n",
                "#     str(test_docs_dir),\n",
                "#     \"my_custom_index\"\n",
                "# )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. é«˜çº§åŠŸèƒ½"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 9.1 è‡ªå®šä¹‰åˆ†å—ç­–ç•¥"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æµ‹è¯•ä¸åŒçš„åˆ†å—å‚æ•°\n",
                "chunk_configs = [\n",
                "    {\"chunk_size\": 300, \"chunk_overlap\": 30},\n",
                "    {\"chunk_size\": 500, \"chunk_overlap\": 50},\n",
                "    {\"chunk_size\": 1000, \"chunk_overlap\": 100},\n",
                "]\n",
                "\n",
                "print(\"æµ‹è¯•ä¸åŒçš„åˆ†å—ç­–ç•¥:\\n\")\n",
                "\n",
                "for config in chunk_configs:\n",
                "    splitter = get_text_splitter(**config)\n",
                "    chunks = splitter.split_documents(documents)\n",
                "    \n",
                "    print(f\"å—å¤§å°: {config['chunk_size']}, é‡å : {config['chunk_overlap']}\")\n",
                "    print(f\"  â†’ ç”Ÿæˆ {len(chunks)} ä¸ªæ–‡æœ¬å—\")\n",
                "    print(f\"  â†’ å¹³å‡å—å¤§å°: {sum(len(c.page_content) for c in chunks) / len(chunks):.0f} å­—ç¬¦\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 9.2 å¤šç´¢å¼•ç®¡ç†"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# æ¼”ç¤ºå¦‚ä½•ç®¡ç†å¤šä¸ªç´¢å¼•\n",
                "manager = IndexManager()\n",
                "\n",
                "# åˆ—å‡ºæ‰€æœ‰ç´¢å¼•\n",
                "indexes = manager.list_indexes()\n",
                "print(f\"å½“å‰ç´¢å¼•åˆ—è¡¨ ({len(indexes)} ä¸ª):\\n\")\n",
                "\n",
                "for idx_name in indexes:\n",
                "    # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨\n",
                "    exists = manager.index_exists(idx_name)\n",
                "    path = manager.get_index_path(idx_name)\n",
                "    \n",
                "    print(f\"ğŸ“š {idx_name}\")\n",
                "    print(f\"   å­˜åœ¨: {exists}\")\n",
                "    print(f\"   è·¯å¾„: {path}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 9.3 åˆ é™¤ç´¢å¼•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# åˆ é™¤æµ‹è¯•ç´¢å¼•ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰\n",
                "# manager.delete_index(\"ml_basics\")\n",
                "# print(\"âœ… ç´¢å¼•å·²åˆ é™¤\")\n",
                "\n",
                "print(\"âš ï¸  å–æ¶ˆæ³¨é‡Šä¸Šé¢çš„ä»£ç ä»¥åˆ é™¤ç´¢å¼•\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. æ€»ç»“\n",
                "\n",
                "é€šè¿‡æœ¬ Notebookï¼Œä½ å·²ç»å­¦ä¹ äº†ï¼š\n",
                "\n",
                "âœ… æ–‡æ¡£åŠ è½½ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰  \n",
                "âœ… æ–‡æœ¬åˆ†å—ç­–ç•¥ä¸å‚æ•°è°ƒä¼˜  \n",
                "âœ… Embedding å‘é‡åŒ–  \n",
                "âœ… å‘é‡å­˜å‚¨çš„åˆ›å»ºä¸ç®¡ç†  \n",
                "âœ… ç´¢å¼•çš„ä¿å­˜ã€åŠ è½½å’Œåˆ é™¤  \n",
                "âœ… æ–‡æ¡£æ£€ç´¢ï¼ˆç›¸ä¼¼åº¦æœç´¢ï¼‰  \n",
                "âœ… RAG Agent çš„åˆ›å»ºä¸é—®ç­”  \n",
                "âœ… å¼•ç”¨æ¥æºçš„è¿½è¸ª  \n",
                "âœ… å¤šç´¢å¼•ç®¡ç†\n",
                "\n",
                "**ä¸‹ä¸€æ­¥**: å­¦ä¹ ç¬¬ 3 é˜¶æ®µ - LangGraph å·¥ä½œæµï¼ˆ`stage_03_workflow.ipynb`ï¼‰"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
