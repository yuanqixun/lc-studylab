"""
èŠå¤© API è·¯ç”±
æä¾› /chat æ¥å£ï¼Œæ”¯æŒæµå¼å’Œéæµå¼å¯¹è¯

è¿™æ˜¯ç¬¬ 1 é˜¶æ®µçš„ API æ¥å£ï¼Œå®ç°ï¼š
1. POST /chat - éæµå¼å¯¹è¯
2. POST /chat/stream - æµå¼å¯¹è¯ï¼ˆSSEï¼‰
3. æ”¯æŒå¯¹è¯å†å²ç®¡ç†
4. æ”¯æŒä¸åŒçš„ Agent æ¨¡å¼
"""

from typing import List, Optional, Dict, Any
from fastapi import APIRouter, HTTPException, Request
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
import json
import asyncio

from agents import create_base_agent
from core.tools import ALL_TOOLS, BASIC_TOOLS
from config import settings, get_logger

logger = get_logger(__name__)

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter(prefix="/chat", tags=["chat"])


# ==================== è¯·æ±‚/å“åº”æ¨¡å‹ ====================

class Message(BaseModel):
    """æ¶ˆæ¯æ¨¡å‹"""
    role: str = Field(..., description="æ¶ˆæ¯è§’è‰²ï¼šuser/assistant/system")
    content: str = Field(..., description="æ¶ˆæ¯å†…å®¹")


class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚æ¨¡å‹"""
    message: str = Field(..., description="ç”¨æˆ·æ¶ˆæ¯", min_length=1)
    chat_history: Optional[List[Message]] = Field(
        default=None,
        description="å¯¹è¯å†å²"
    )
    mode: str = Field(
        default="default",
        description="Agent æ¨¡å¼ï¼šdefault/coding/research/concise/detailed"
    )
    use_tools: bool = Field(
        default=True,
        description="æ˜¯å¦å¯ç”¨å·¥å…·"
    )
    use_advanced_tools: bool = Field(
        default=False,
        description="æ˜¯å¦å¯ç”¨é«˜çº§å·¥å…·ï¼ˆéœ€è¦ API Keyï¼‰"
    )
    streaming: bool = Field(
        default=False,
        description="æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡ºï¼ˆæ­¤å­—æ®µåœ¨éæµå¼æ¥å£ä¸­æ— æ•ˆï¼‰"
    )


class ChatResponse(BaseModel):
    """èŠå¤©å“åº”æ¨¡å‹"""
    message: str = Field(..., description="AI å›å¤")
    mode: str = Field(..., description="ä½¿ç”¨çš„ Agent æ¨¡å¼")
    tools_used: List[str] = Field(default_factory=list, description="ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨")
    success: bool = Field(default=True, description="æ˜¯å¦æˆåŠŸ")
    error: Optional[str] = Field(default=None, description="é”™è¯¯ä¿¡æ¯")


# ==================== è¾…åŠ©å‡½æ•° ====================

def get_tools_for_request(use_tools: bool, use_advanced_tools: bool) -> List:
    """
    æ ¹æ®è¯·æ±‚å‚æ•°è·å–å·¥å…·åˆ—è¡¨
    
    Args:
        use_tools: æ˜¯å¦ä½¿ç”¨å·¥å…·
        use_advanced_tools: æ˜¯å¦ä½¿ç”¨é«˜çº§å·¥å…·
        
    Returns:
        å·¥å…·åˆ—è¡¨
    """
    if not use_tools:
        return []
    
    if use_advanced_tools:
        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†å¿…è¦çš„ API Key
        if not settings.tavily_api_key:
            logger.warning("âš ï¸ è¯·æ±‚ä½¿ç”¨é«˜çº§å·¥å…·ï¼Œä½†æœªé…ç½® Tavily API Key")
            return BASIC_TOOLS
        return ALL_TOOLS
    
    return BASIC_TOOLS


def convert_chat_history(messages: Optional[List[Message]]) -> List:
    """
    å°† API çš„æ¶ˆæ¯æ ¼å¼è½¬æ¢ä¸º LangChain çš„æ¶ˆæ¯æ ¼å¼
    
    Args:
        messages: API æ¶ˆæ¯åˆ—è¡¨
        
    Returns:
        LangChain æ¶ˆæ¯åˆ—è¡¨
    """
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    
    if not messages:
        return []
    
    langchain_messages = []
    for msg in messages:
        if msg.role == "user":
            langchain_messages.append(HumanMessage(content=msg.content))
        elif msg.role == "assistant":
            langchain_messages.append(AIMessage(content=msg.content))
        elif msg.role == "system":
            langchain_messages.append(SystemMessage(content=msg.content))
    
    return langchain_messages


# ==================== API ç«¯ç‚¹ ====================

@router.post("/", response_model=ChatResponse)
async def chat(request: ChatRequest) -> ChatResponse:
    """
    éæµå¼èŠå¤©æ¥å£
    
    æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯ï¼Œè¿”å› AI çš„å®Œæ•´å›å¤ã€‚
    é€‚åˆéœ€è¦ä¸€æ¬¡æ€§è·å–å®Œæ•´å“åº”çš„åœºæ™¯ã€‚
    
    Args:
        request: èŠå¤©è¯·æ±‚
        
    Returns:
        èŠå¤©å“åº”
        
    Example:
        ```bash
        curl -X POST "http://localhost:8000/chat" \\
          -H "Content-Type: application/json" \\
          -d '{
            "message": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±",
            "mode": "default",
            "use_tools": true
          }'
        ```
    """
    logger.info(f"ğŸ“¨ æ”¶åˆ°èŠå¤©è¯·æ±‚: {request.message[:50]}...")
    logger.debug(f"   æ¨¡å¼: {request.mode}, å·¥å…·: {request.use_tools}")
    
    try:
        # è·å–å·¥å…·åˆ—è¡¨
        tools = get_tools_for_request(request.use_tools, request.use_advanced_tools)
        
        # åˆ›å»º Agent
        agent = create_base_agent(
            tools=tools,
            prompt_mode=request.mode,
            # streaming=False,  # éæµå¼æ¥å£
        )
        
        # è½¬æ¢å¯¹è¯å†å²
        chat_history = convert_chat_history(request.chat_history)
        
        # è°ƒç”¨ Agent
        response = await agent.ainvoke(
            input_text=request.message,
            chat_history=chat_history,
        )
        
        # æ„å»ºå“åº”
        tool_names = [tool.name for tool in tools]
        
        logger.info(f"âœ… èŠå¤©è¯·æ±‚å¤„ç†å®Œæˆï¼Œå“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
        
        return ChatResponse(
            message=response,
            mode=request.mode,
            tools_used=tool_names,
            success=True,
        )
        
    except Exception as e:
        error_msg = f"å¤„ç†èŠå¤©è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        
        return ChatResponse(
            message="æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ã€‚",
            mode=request.mode,
            tools_used=[],
            success=False,
            error=str(e),
        )


@router.post("/stream")
async def chat_stream(request: ChatRequest):
    """
    æµå¼èŠå¤©æ¥å£ï¼ˆSSE - Server-Sent Eventsï¼‰
    
    æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯ï¼Œä»¥æµå¼æ–¹å¼è¿”å› AI çš„å›å¤ã€‚
    é€‚åˆéœ€è¦å®æ—¶æ˜¾ç¤ºç”Ÿæˆè¿‡ç¨‹çš„åœºæ™¯ã€‚
    
    Args:
        request: èŠå¤©è¯·æ±‚
        
    Returns:
        SSE æµå¼å“åº”
        
    Example:
        ```bash
        curl -X POST "http://localhost:8000/chat/stream" \\
          -H "Content-Type: application/json" \\
          -d '{
            "message": "è®²ä¸€ä¸ªå…³äºç¼–ç¨‹çš„ç¬‘è¯",
            "mode": "default"
          }'
        ```
        
    å“åº”æ ¼å¼ï¼ˆSSEï¼‰:
        ```
        data: {"type": "start", "message": "å¼€å§‹ç”Ÿæˆ..."}
        
        data: {"type": "chunk", "content": "ä»å‰"}
        
        data: {"type": "chunk", "content": "æœ‰ä¸ª"}
        
        data: {"type": "chunk", "content": "ç¨‹åºå‘˜"}
        
        data: {"type": "end", "message": "ç”Ÿæˆå®Œæˆ"}
        ```
    """
    logger.info(f"ğŸŒŠ æ”¶åˆ°æµå¼èŠå¤©è¯·æ±‚: {request.message[:50]}...")
    
    async def generate():
        """SSE ç”Ÿæˆå™¨å‡½æ•°"""
        try:
            # å‘é€å¼€å§‹äº‹ä»¶
            yield f"data: {json.dumps({'type': 'start', 'message': 'å¼€å§‹ç”Ÿæˆ...'}, ensure_ascii=False)}\n\n"
            
            # è·å–å·¥å…·åˆ—è¡¨
            tools = get_tools_for_request(request.use_tools, request.use_advanced_tools)
            
            # åˆ›å»º Agentï¼ˆå¯ç”¨æµå¼ï¼‰
            agent = create_base_agent(
                tools=tools,
                prompt_mode=request.mode,
                # streaming=True,
            )
            
            # è½¬æ¢å¯¹è¯å†å²
            chat_history = convert_chat_history(request.chat_history)
            
            # æµå¼è°ƒç”¨ Agent
            async for chunk in agent.astream(
                input_text=request.message,
                chat_history=chat_history,
            ):
                # å‘é€å†…å®¹å—
                chunk_data = {
                    "type": "chunk",
                    "content": chunk,
                }
                yield f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n"
                
                # å°å»¶è¿Ÿï¼Œè®©å‰ç«¯æœ‰æ—¶é—´å¤„ç†
                await asyncio.sleep(0.01)
            
            # å‘é€ç»“æŸäº‹ä»¶
            yield f"data: {json.dumps({'type': 'end', 'message': 'ç”Ÿæˆå®Œæˆ'}, ensure_ascii=False)}\n\n"
            
            logger.info("âœ… æµå¼èŠå¤©è¯·æ±‚å¤„ç†å®Œæˆ")
            
        except Exception as e:
            error_msg = f"æµå¼å¤„ç†å‡ºé”™: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            
            # å‘é€é”™è¯¯äº‹ä»¶
            error_data = {
                "type": "error",
                "message": "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯",
                "error": str(e),
            }
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
    
    # è¿”å› SSE å“åº”
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # ç¦ç”¨ Nginx ç¼“å†²
        },
    )


@router.get("/health")
async def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£
    
    Returns:
        å¥åº·çŠ¶æ€
    """
    return {
        "status": "healthy",
        "service": "chat",
        "version": settings.app_version,
    }


@router.get("/modes")
async def get_available_modes():
    """
    è·å–å¯ç”¨çš„ Agent æ¨¡å¼åˆ—è¡¨
    
    Returns:
        æ¨¡å¼åˆ—è¡¨åŠå…¶æè¿°
    """
    from core.prompts import SYSTEM_PROMPTS
    
    modes = {}
    for mode_name in SYSTEM_PROMPTS.keys():
        # æå–æ¯ä¸ªæ¨¡å¼çš„ç®€çŸ­æè¿°
        prompt = SYSTEM_PROMPTS[mode_name]
        first_line = prompt.split('\n')[0]
        modes[mode_name] = first_line
    
    return {
        "modes": modes,
        "default": "default",
    }

