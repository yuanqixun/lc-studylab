# ğŸ”„ LangChain V1.0.0 é‡æ„è¯´æ˜

## ğŸ“… é‡æ„ä¿¡æ¯

- **æ—¥æœŸï¼š** 2025-11-05
- **åŸå› ï¼š** é€‚é… LangChain V1.0.0 çš„å…¨æ–° API
- **å‚è€ƒæ–‡æ¡£ï¼š**
  - https://docs.langchain.com/oss/python/langchain/agents
  - https://reference.langchain.com/python/langchain/agents/
  - https://reference.langchain.com/python/langchain/models/

## ğŸ¯ é‡å¤§å˜æ›´

### 1. Agent åˆ›å»ºæ–¹å¼å®Œå…¨æ”¹å˜

#### æ—§æ–¹å¼ï¼ˆV0.xï¼‰
```python
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate

# åˆ›å»º prompt
prompt = ChatPromptTemplate.from_messages([...])

# åˆ›å»º agent
agent = create_tool_calling_agent(llm=model, tools=tools, prompt=prompt)

# åˆ›å»º executor
agent_executor = AgentExecutor(agent=agent, tools=tools, ...)
```

#### æ–°æ–¹å¼ï¼ˆV1.0.0ï¼‰âœ…
```python
from langchain.agents import create_agent

# ä¸€æ­¥åˆ›å»ºï¼Œè¿”å› CompiledStateGraph
graph = create_agent(
    model="openai:gpt-4o",  # å­—ç¬¦ä¸²æ ‡è¯†ç¬¦æˆ– BaseChatModel å®ä¾‹
    tools=tools,
    system_prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹",
    debug=False,
)
```

**å…³é”®åŒºåˆ«ï¼š**
- âœ… ä¸å†éœ€è¦ `create_tool_calling_agent`
- âœ… ä¸å†éœ€è¦ `AgentExecutor`
- âœ… ä¸å†éœ€è¦æ‰‹åŠ¨åˆ›å»º `ChatPromptTemplate`
- âœ… `create_agent` ç›´æ¥è¿”å› `CompiledStateGraph`ï¼ˆåŸºäº LangGraphï¼‰
- âœ… æ¨¡å‹å¯ä»¥ç”¨å­—ç¬¦ä¸²æ ‡è¯†ç¬¦ï¼ˆå¦‚ "openai:gpt-4o"ï¼‰

### 2. è¾“å…¥æ ¼å¼å˜åŒ–

#### æ—§æ–¹å¼
```python
agent_executor.invoke({
    "input": "ä½ å¥½",
    "chat_history": [...],
})
```

#### æ–°æ–¹å¼âœ…
```python
graph.invoke({
    "messages": [
        HumanMessage(content="ä½ å¥½"),
        # ... å…¶ä»–æ¶ˆæ¯
    ],
})
```

**å…³é”®åŒºåˆ«ï¼š**
- âœ… ä½¿ç”¨ `messages` é”®è€Œä¸æ˜¯ `input` å’Œ `chat_history`
- âœ… ç›´æ¥ä¼ é€’æ¶ˆæ¯åˆ—è¡¨

### 3. è¾“å‡ºæ ¼å¼å˜åŒ–

#### æ—§æ–¹å¼
```python
result = agent_executor.invoke(...)
output = result["output"]  # å­—ç¬¦ä¸²
```

#### æ–°æ–¹å¼âœ…
```python
result = graph.invoke(...)
messages = result["messages"]  # æ¶ˆæ¯åˆ—è¡¨
# éœ€è¦æå–æœ€åä¸€æ¡ AI æ¶ˆæ¯
for msg in reversed(messages):
    if isinstance(msg, AIMessage):
        output = msg.content
        break
```

### 4. æµå¼è¾“å‡ºå˜åŒ–

#### æ—§æ–¹å¼
```python
for chunk in agent_executor.stream(...):
    if "output" in chunk:
        print(chunk["output"])
```

#### æ–°æ–¹å¼âœ…
```python
for chunk in graph.stream(..., stream_mode="messages"):
    # chunk æ˜¯ (message, metadata) å…ƒç»„
    if isinstance(chunk, tuple):
        message, metadata = chunk
        if isinstance(message, AIMessage):
            print(message.content)
```

**æµå¼æ¨¡å¼ï¼š**
- `"messages"` - æµå¼è¿”å›æ¶ˆæ¯ï¼ˆæ¨èï¼‰
- `"updates"` - è¿”å›çŠ¶æ€æ›´æ–°
- `"values"` - è¿”å›å®Œæ•´çŠ¶æ€å€¼

## ğŸ“ å·²é‡æ„çš„æ–‡ä»¶

### 1. `agents/base_agent.py` âœ…

**ä¸»è¦å˜æ›´ï¼š**
- ä½¿ç”¨ `langchain.agents.create_agent` æ›¿ä»£ `create_tool_calling_agent` + `AgentExecutor`
- `__init__` æ–¹æ³•ç®€åŒ–ï¼Œç›´æ¥è°ƒç”¨ `create_agent`
- `model` å‚æ•°æ”¯æŒå­—ç¬¦ä¸²æ ‡è¯†ç¬¦ï¼ˆå¦‚ "openai:gpt-4o"ï¼‰
- ç§»é™¤ `streaming`ã€`max_iterations`ã€`max_execution_time`ã€`verbose` å‚æ•°
- æ·»åŠ  `debug` å‚æ•°ï¼ˆå¯¹åº” `create_agent` çš„ debugï¼‰
- `invoke`/`stream`/`ainvoke`/`astream` æ–¹æ³•é€‚é…æ–°çš„è¾“å…¥/è¾“å‡ºæ ¼å¼

**æ–°å¢å±æ€§ï¼š**
```python
self.graph  # CompiledStateGraph å®ä¾‹ï¼ˆæ›¿ä»£ agent_executorï¼‰
```

**ç¤ºä¾‹ï¼š**
```python
# åˆ›å»º Agent
agent = BaseAgent(
    model="openai:gpt-4o",  # æˆ– None ä½¿ç”¨é»˜è®¤é…ç½®
    tools=[get_current_time, calculator],
    prompt_mode="default",
    debug=False,
)

# è°ƒç”¨
response = agent.invoke("ç°åœ¨å‡ ç‚¹ï¼Ÿ")

# æµå¼è°ƒç”¨
for chunk in agent.stream("è®²ä¸ªç¬‘è¯"):
    print(chunk, end="", flush=True)
```

### 2. `core/models.py` âœ…

**æ–°å¢å‡½æ•°ï¼š**
```python
def get_model_string(
    model_name: Optional[str] = None,
    provider: str = "openai",
) -> str:
    """
    è·å–æ¨¡å‹æ ‡è¯†ç¬¦å­—ç¬¦ä¸²
    
    è¿”å›æ ¼å¼ï¼š" provider:model_name"
    ä¾‹å¦‚ï¼š"openai:gpt-4o"
    """
```

**ç”¨é€”ï¼š**
- ä¸º `create_agent` ç”Ÿæˆæ­£ç¡®çš„æ¨¡å‹æ ‡è¯†ç¬¦å­—ç¬¦ä¸²
- æ”¯æŒå¤šä¸ªæä¾›å•†ï¼ˆopenai, anthropic, etc.ï¼‰

## ğŸ”§ å¾…é‡æ„çš„æ–‡ä»¶

### 3. `api/routers/chat.py` â³

**éœ€è¦å˜æ›´ï¼š**
- é€‚é…æ–°çš„ Agent è°ƒç”¨æ–¹å¼
- æ›´æ–°æµå¼è¾“å‡ºå¤„ç†é€»è¾‘

### 4. `scripts/demo_cli.py` â³

**éœ€è¦å˜æ›´ï¼š**
- é€‚é…æ–°çš„ Agent åˆ›å»ºå‚æ•°
- ç§»é™¤ `streaming` å‚æ•°ç›¸å…³é€»è¾‘

### 5. `scripts/test_basic.py` â³

**éœ€è¦å˜æ›´ï¼š**
- æ›´æ–°æµ‹è¯•ç”¨ä¾‹ä»¥é€‚é…æ–° API

## ğŸ“š æ–° API å‚è€ƒ

### `create_agent` å‚æ•°

æ ¹æ® [å®˜æ–¹æ–‡æ¡£](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent)ï¼š

```python
create_agent(
    model: str | BaseChatModel,           # æ¨¡å‹æ ‡è¯†ç¬¦æˆ–å®ä¾‹
    tools: Sequence[BaseTool] | None,     # å·¥å…·åˆ—è¡¨
    system_prompt: str | None = None,     # ç³»ç»Ÿæç¤ºè¯
    middleware: Sequence[...] = (),       # ä¸­é—´ä»¶
    response_format: ... | None = None,   # å“åº”æ ¼å¼
    state_schema: type[...] | None = None,# çŠ¶æ€ schema
    context_schema: type[...] | None = None, # ä¸Šä¸‹æ–‡ schema
    checkpointer: Checkpointer | None = None, # çŠ¶æ€æŒä¹…åŒ–
    store: BaseStore | None = None,       # è·¨çº¿ç¨‹å­˜å‚¨
    interrupt_before: list[str] | None = None, # å‰ç½®ä¸­æ–­ç‚¹
    interrupt_after: list[str] | None = None,  # åç½®ä¸­æ–­ç‚¹
    debug: bool = False,                  # è°ƒè¯•æ¨¡å¼
    name: str | None = None,              # Agent åç§°
    cache: BaseCache | None = None,       # ç¼“å­˜
) -> CompiledStateGraph
```

### æ¨¡å‹æ ‡è¯†ç¬¦æ ¼å¼

æ”¯æŒçš„æ ¼å¼ï¼š
- `"openai:gpt-4o"` - OpenAI GPT-4o
- `"openai:gpt-4o-mini"` - OpenAI GPT-4o Mini
- `"anthropic:claude-3-5-sonnet-20241022"` - Anthropic Claude
- `"google:gemini-pro"` - Google Gemini
- æˆ–ç›´æ¥ä¼ é€’ `BaseChatModel` å®ä¾‹

### CompiledStateGraph æ–¹æ³•

```python
# åŒæ­¥è°ƒç”¨
result = graph.invoke({"messages": [...]})

# å¼‚æ­¥è°ƒç”¨
result = await graph.ainvoke({"messages": [...]})

# æµå¼è°ƒç”¨
for chunk in graph.stream({"messages": [...]}, stream_mode="messages"):
    # å¤„ç† chunk

# å¼‚æ­¥æµå¼è°ƒç”¨
async for chunk in graph.astream({"messages": [...]}, stream_mode="messages"):
    # å¤„ç† chunk
```

## ğŸ¯ è¿ç§»æ£€æŸ¥æ¸…å•

- [x] æ›´æ–° `agents/base_agent.py`
  - [x] ä½¿ç”¨ `create_agent` æ›¿ä»£æ—§ API
  - [x] é€‚é…æ–°çš„è¾“å…¥/è¾“å‡ºæ ¼å¼
  - [x] æ›´æ–°æµå¼è¾“å‡ºå¤„ç†
  - [x] æ›´æ–°æ–‡æ¡£å­—ç¬¦ä¸²

- [x] æ›´æ–° `core/models.py`
  - [x] æ·»åŠ  `get_model_string` å‡½æ•°
  - [x] æ›´æ–°æ–‡æ¡£è¯´æ˜

- [ ] æ›´æ–° `api/routers/chat.py`
  - [ ] é€‚é…æ–°çš„ Agent æ¥å£
  - [ ] æ›´æ–°æµå¼å“åº”å¤„ç†

- [ ] æ›´æ–° `scripts/demo_cli.py`
  - [ ] ç§»é™¤ `streaming` å‚æ•°
  - [ ] é€‚é…æ–°çš„ Agent åˆ›å»ºæ–¹å¼

- [ ] æ›´æ–° `scripts/test_basic.py`
  - [ ] æ›´æ–°æµ‹è¯•ç”¨ä¾‹

- [ ] æ›´æ–°æ–‡æ¡£
  - [ ] README.md
  - [ ] QUICKSTART.md
  - [ ] STAGE1_COMPLETION.md

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ä½¿ç”¨å­—ç¬¦ä¸²æ ‡è¯†ç¬¦

**æ¨èï¼š**
```python
agent = BaseAgent(model="openai:gpt-4o")
```

**åŸå› ï¼š**
- è‡ªåŠ¨ä»ç¯å¢ƒå˜é‡è¯»å– API Key
- ç®€åŒ–é…ç½®ç®¡ç†
- æ”¯æŒå¤šä¸ªæä¾›å•†

### 2. åˆ©ç”¨ debug æ¨¡å¼

```python
agent = BaseAgent(debug=True)
```

**ç”¨é€”ï¼š**
- æŸ¥çœ‹è¯¦ç»†çš„æ‰§è¡Œæ—¥å¿—
- è°ƒè¯•å·¥å…·è°ƒç”¨
- ç†è§£ Agent æ‰§è¡Œæµç¨‹

### 3. ä½¿ç”¨ checkpointer å®ç°è®°å¿†

```python
from langgraph.checkpoint.memory import MemorySaver

agent = BaseAgent(
    checkpointer=MemorySaver(),
)
```

**ç”¨é€”ï¼š**
- æŒä¹…åŒ–å¯¹è¯çŠ¶æ€
- å®ç°å¤šè½®å¯¹è¯è®°å¿†
- æ”¯æŒå¯¹è¯æ¢å¤

## ğŸ”— å‚è€ƒèµ„æº

- [LangChain Agents æ–‡æ¡£](https://docs.langchain.com/oss/python/langchain/agents)
- [create_agent API å‚è€ƒ](https://reference.langchain.com/python/langchain/agents/)
- [LangChain Models æ–‡æ¡£](https://docs.langchain.com/oss/python/langchain/models)
- [LangGraph æ–‡æ¡£](https://docs.langchain.com/oss/python/langgraph)

## ğŸ‰ æ€»ç»“

LangChain V1.0.0 çš„æ–° `create_agent` API å¤§å¤§ç®€åŒ–äº† Agent çš„åˆ›å»ºè¿‡ç¨‹ï¼š

**ä¼˜ç‚¹ï¼š**
- âœ… æ›´ç®€æ´çš„ API
- âœ… åŸºäº LangGraph çš„å¼ºå¤§åŠŸèƒ½
- âœ… æ›´å¥½çš„çŠ¶æ€ç®¡ç†
- âœ… å†…ç½®çš„æµå¼æ”¯æŒ
- âœ… æ”¯æŒä¸­é—´ä»¶å’Œæ‰©å±•

**æ³¨æ„äº‹é¡¹ï¼š**
- âš ï¸ è¾“å…¥/è¾“å‡ºæ ¼å¼å®Œå…¨ä¸åŒ
- âš ï¸ éœ€è¦é€‚é…æ‰€æœ‰è°ƒç”¨ä»£ç 
- âš ï¸ æµå¼è¾“å‡ºå¤„ç†é€»è¾‘æ”¹å˜

---

**æœ€åæ›´æ–°ï¼š** 2025-11-05
**çŠ¶æ€ï¼š** è¿›è¡Œä¸­ï¼ˆ3/5 å®Œæˆï¼‰

