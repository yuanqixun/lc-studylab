# ç¬¬ 2 é˜¶æ®µï¼šRAG çŸ¥è¯†åº“æ¨¡å— - ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

ç¬¬ 2 é˜¶æ®µå®ç°äº†å®Œæ•´çš„ RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»ç»Ÿï¼Œæ”¯æŒï¼š
- ğŸ“„ å¤šæ ¼å¼æ–‡æ¡£åŠ è½½ï¼ˆPDFã€Markdownã€TXTã€HTMLã€JSONï¼‰
- âœ‚ï¸ æ™ºèƒ½æ–‡æœ¬åˆ†å—
- ğŸ”¢ å‘é‡åŒ–å’Œå‘é‡å­˜å‚¨ï¼ˆFAISSï¼‰
- ğŸ” å¤šç§æ£€ç´¢ç­–ç•¥
- ğŸ¤– RAG Agentï¼ˆåŸºäºæ£€ç´¢çš„æ™ºèƒ½é—®ç­”ï¼‰
- ğŸŒ HTTP API æ¥å£
- ğŸ’» CLI å‘½ä»¤è¡Œå·¥å…·

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd backend
pip install -r requirements.txt
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

ç¡®ä¿ `.env` æ–‡ä»¶ä¸­é…ç½®äº† OpenAI API Keyï¼š

```bash
OPENAI_API_KEY=your_api_key_here
```

### 3. åˆ›å»ºç¬¬ä¸€ä¸ªç´¢å¼•

ä½¿ç”¨ CLI å·¥å…·åˆ›å»ºç´¢å¼•ï¼š

```bash
python scripts/rag_cli.py index create test_index data/documents/test --description "æµ‹è¯•æ–‡æ¡£ç´¢å¼•"
```

### 4. æŸ¥è¯¢ç´¢å¼•

```bash
python scripts/rag_cli.py query test_index "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
```

### 5. äº¤äº’æ¨¡å¼

```bash
python scripts/rag_cli.py interactive test_index
```

## ğŸ“š æ ¸å¿ƒåŠŸèƒ½

### 1. æ–‡æ¡£åŠ è½½

æ”¯æŒçš„æ–‡æ¡£æ ¼å¼ï¼š
- PDF (.pdf)
- Markdown (.md, .mdx)
- æ–‡æœ¬æ–‡ä»¶ (.txt)
- HTML (.html, .htm)
- JSON (.json)

**ä»£ç ç¤ºä¾‹ï¼š**

```python
from rag import load_document, load_directory

# åŠ è½½å•ä¸ªæ–‡æ¡£
documents = load_document("document.pdf")

# åŠ è½½æ•´ä¸ªç›®å½•
documents = load_directory("data/documents/")

# åŠ è½½ç‰¹å®šæ ¼å¼
documents = load_directory(
    "data/documents/",
    glob_pattern="**/*.md"
)
```

### 2. æ–‡æœ¬åˆ†å—

æ”¯æŒå¤šç§åˆ†å—ç­–ç•¥ï¼š
- `recursive`: é€’å½’å­—ç¬¦åˆ†å—ï¼ˆæ¨èï¼‰
- `character`: ç®€å•å­—ç¬¦åˆ†å—
- `markdown`: Markdown ä¸“ç”¨åˆ†å—
- `token`: åŸºäº Token çš„åˆ†å—

**ä»£ç ç¤ºä¾‹ï¼š**

```python
from rag import split_documents

# ä½¿ç”¨é»˜è®¤é…ç½®
chunks = split_documents(documents)

# è‡ªå®šä¹‰å‚æ•°
chunks = split_documents(
    documents,
    splitter_type="recursive",
    chunk_size=1000,
    chunk_overlap=200
)
```

### 3. å‘é‡åŒ–å’Œå­˜å‚¨

ä½¿ç”¨ OpenAI Embeddings å’Œ FAISS å‘é‡åº“ï¼š

```python
from rag import get_embeddings, create_vector_store, save_vector_store

# åˆ›å»º embeddings
embeddings = get_embeddings()

# åˆ›å»ºå‘é‡åº“
vector_store = create_vector_store(chunks, embeddings)

# ä¿å­˜å‘é‡åº“
save_vector_store(vector_store, "data/indexes/my_index")
```

### 4. æ£€ç´¢

æ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥ï¼š

```python
from rag import load_vector_store, create_retriever

# åŠ è½½å‘é‡åº“
vector_store = load_vector_store("data/indexes/my_index", embeddings)

# ç›¸ä¼¼åº¦æ£€ç´¢
retriever = create_retriever(vector_store, search_type="similarity", k=4)

# MMR æ£€ç´¢ï¼ˆæ›´å¤šæ ·åŒ–ï¼‰
retriever = create_retriever(vector_store, search_type="mmr", k=4, fetch_k=20)

# é˜ˆå€¼è¿‡æ»¤
retriever = create_retriever(
    vector_store,
    search_type="similarity_score_threshold",
    score_threshold=0.7
)

# ä½¿ç”¨æ£€ç´¢å™¨
docs = retriever.invoke("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")
```

### 5. RAG Agent

åˆ›å»ºæ”¯æŒæ£€ç´¢çš„æ™ºèƒ½é—®ç­” Agentï¼š

```python
from rag import create_rag_agent, query_rag_agent

# åˆ›å»º RAG Agent
agent = create_rag_agent(retriever)

# æŸ¥è¯¢
result = query_rag_agent(agent, "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")
print(result["answer"])
print(result["sources"])

# æµå¼æŸ¥è¯¢
agent_streaming = create_rag_agent(retriever, streaming=True)
for chunk in agent_streaming.stream({"input": "è§£é‡Šæ·±åº¦å­¦ä¹ "}):
    if "output" in chunk:
        print(chunk["output"], end="", flush=True)
```

### 6. ç´¢å¼•ç®¡ç†

ä½¿ç”¨ IndexManager ç»Ÿä¸€ç®¡ç†ç´¢å¼•ï¼š

```python
from rag import IndexManager, get_embeddings, split_documents, load_directory

manager = IndexManager()

# åˆ›å»ºç´¢å¼•
documents = load_directory("data/documents/test")
chunks = split_documents(documents)
embeddings = get_embeddings()

manager.create_index(
    name="my_docs",
    documents=chunks,
    embeddings=embeddings,
    description="æˆ‘çš„æ–‡æ¡£é›†åˆ"
)

# åˆ—å‡ºæ‰€æœ‰ç´¢å¼•
indexes = manager.list_indexes()

# è·å–ç´¢å¼•ä¿¡æ¯
info = manager.get_index_info("my_docs")

# åŠ è½½ç´¢å¼•
vector_store = manager.load_index("my_docs", embeddings)

# æ›´æ–°ç´¢å¼•
new_docs = load_directory("data/documents/new")
new_chunks = split_documents(new_docs)
manager.update_index("my_docs", new_chunks, embeddings)

# åˆ é™¤ç´¢å¼•
manager.delete_index("my_docs")
```

### 5. æ™ºèƒ½ç´¢å¼•æ›´æ–° â­

**æ¨èä½¿ç”¨æ™ºèƒ½æ›´æ–°è„šæœ¬ï¼Œè‡ªåŠ¨æ£€æµ‹æ–°æ–‡æ¡£å¹¶å¢é‡æ›´æ–°ï¼š**

```bash
# 1. æ·»åŠ æ–°æ–‡æ¡£åˆ°ç›®å½•
cp new_document.md data/documents/test/

# 2. è¿è¡Œæ™ºèƒ½æ›´æ–°ï¼ˆåªå¤„ç†æ–°æ–‡æ¡£ï¼‰
python scripts/update_index.py test_index data/documents/test

# 3. æŸ¥è¯¢éªŒè¯
python scripts/rag_cli.py query test_index "æ–°æ–‡æ¡£çš„å†…å®¹"
```

**ä¸»è¦ç‰¹æ€§ï¼š**

âœ… **è‡ªåŠ¨æ£€æµ‹æ–°æ–‡æ¡£** - åªå¤„ç†æœªç´¢å¼•çš„æ–‡æ¡£  
âœ… **æ–‡ä»¶è·Ÿè¸ª** - è‡ªåŠ¨è®°å½•å·²å¤„ç†çš„æ–‡æ¡£  
âœ… **å¢é‡æ›´æ–°** - èŠ‚çœæ—¶é—´å’Œ API æˆæœ¬  
âœ… **æ”¯æŒé‡å»º** - éœ€è¦æ—¶å¯ä»¥å®Œå…¨é‡å»ºç´¢å¼•

**è¯¦ç»†ä½¿ç”¨æ–¹æ³•ï¼š**

```bash
# å¢é‡æ›´æ–°ï¼ˆæ¨èï¼‰
python scripts/update_index.py test_index data/documents/test

# å¼ºåˆ¶é‡å»ºæ•´ä¸ªç´¢å¼•
python scripts/update_index.py test_index data/documents/test --rebuild

# æŸ¥çœ‹å¸®åŠ©
python scripts/update_index.py --help
```

**å·¥ä½œæµç¨‹ï¼š**

```bash
# æ­¥éª¤ 1: æ·»åŠ æ–°æ–‡æ¡£
echo "# æ–°ä¸»é¢˜\nè¿™æ˜¯æ–°å†…å®¹..." > data/documents/test/new_topic.md

# æ­¥éª¤ 2: æ›´æ–°ç´¢å¼•
python scripts/update_index.py test_index data/documents/test
# è¾“å‡º: ğŸ“„ å‘ç° 1 ä¸ªæ–°æ–‡æ¡£: new_topic.md

# æ­¥éª¤ 3: éªŒè¯æŸ¥è¯¢
python scripts/rag_cli.py query test_index "æ–°ä¸»é¢˜"
```

**è·Ÿè¸ªæ–‡ä»¶ä½ç½®ï¼š**
```
data/indexes/test_index/tracked_files.json
```

**ğŸ“– å®Œæ•´æ–‡æ¡£ï¼š** [æ™ºèƒ½ç´¢å¼•æ›´æ–°æŒ‡å—](INDEX_UPDATE_GUIDE.md)

## ğŸŒ HTTP API

### å¯åŠ¨æœåŠ¡å™¨

```bash
python api/http_server.py
```

æœåŠ¡å™¨å¯åŠ¨åï¼Œè®¿é—® http://localhost:8000/docs æŸ¥çœ‹ API æ–‡æ¡£ã€‚

### API ç«¯ç‚¹

#### 1. åˆ›å»ºç´¢å¼•

```bash
curl -X POST "http://localhost:8000/rag/index" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "my_docs",
    "directory_path": "data/documents/test",
    "description": "æµ‹è¯•æ–‡æ¡£ç´¢å¼•",
    "chunk_size": 1000
  }'
```

#### 2. åˆ—å‡ºç´¢å¼•

```bash
curl "http://localhost:8000/rag/index/list"
```

#### 3. è·å–ç´¢å¼•ä¿¡æ¯

```bash
curl "http://localhost:8000/rag/index/my_docs"
```

#### 4. RAG æŸ¥è¯¢

```bash
curl -X POST "http://localhost:8000/rag/query" \
  -H "Content-Type: application/json" \
  -d '{
    "index_name": "my_docs",
    "query": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
    "k": 4
  }'
```

#### 5. æµå¼æŸ¥è¯¢

```bash
curl -X POST "http://localhost:8000/rag/query/stream" \
  -H "Content-Type: application/json" \
  -d '{
    "index_name": "my_docs",
    "query": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
  }'
```

#### 6. çº¯æ£€ç´¢

```bash
curl -X POST "http://localhost:8000/rag/search" \
  -H "Content-Type: application/json" \
  -d '{
    "index_name": "my_docs",
    "query": "æœºå™¨å­¦ä¹ ",
    "k": 3
  }'
```

#### 7. åˆ é™¤ç´¢å¼•

```bash
curl -X DELETE "http://localhost:8000/rag/index/my_docs"
```

## ğŸ’» CLI å·¥å…·

### ç´¢å¼•ç®¡ç†

```bash
# åˆ›å»ºç´¢å¼•
python scripts/rag_cli.py index create my_docs data/documents/test \
  --description "æˆ‘çš„æ–‡æ¡£" \
  --chunk-size 1000 \
  --chunk-overlap 200

# åˆ—å‡ºæ‰€æœ‰ç´¢å¼•
python scripts/rag_cli.py index list

# æŸ¥çœ‹ç´¢å¼•ä¿¡æ¯
python scripts/rag_cli.py index info my_docs

# åˆ é™¤ç´¢å¼•
python scripts/rag_cli.py index delete my_docs
```

### æŸ¥è¯¢

```bash
# RAG æŸ¥è¯¢
python scripts/rag_cli.py query my_docs "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ" --k 4 --show-sources

# çº¯æ£€ç´¢
python scripts/rag_cli.py search my_docs "æœºå™¨å­¦ä¹ " --k 3

# äº¤äº’æ¨¡å¼
python scripts/rag_cli.py interactive my_docs
```

## âš™ï¸ é…ç½®å‚æ•°

åœ¨ `config/settings.py` ä¸­é…ç½® RAG å‚æ•°ï¼š

```python
# Embedding é…ç½®
embedding_model = "text-embedding-3-small"  # æˆ– "text-embedding-3-large"
embedding_batch_size = 100

# æ–‡æœ¬åˆ†å—é…ç½®
chunk_size = 1000           # åˆ†å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
chunk_overlap = 200         # åˆ†å—é‡å å¤§å°

# å‘é‡åº“é…ç½®
vector_store_type = "faiss"  # å‘é‡åº“ç±»å‹
vector_store_path = "data/indexes"  # ç´¢å¼•å­˜å‚¨è·¯å¾„

# æ£€ç´¢é…ç½®
retriever_search_type = "similarity"  # similarity, mmr, similarity_score_threshold
retriever_k = 4                       # è¿”å›æ–‡æ¡£æ•°é‡
retriever_score_threshold = 0.5       # ç›¸ä¼¼åº¦é˜ˆå€¼
retriever_fetch_k = 20                # MMR å€™é€‰æ•°é‡

# RAG Agent é…ç½®
rag_agent_max_iterations = 10
rag_agent_return_source_documents = True
```

## ğŸ“Š æœ€ä½³å®è·µ

### 1. é€‰æ‹©åˆé€‚çš„åˆ†å—å¤§å°

- **é€šç”¨æ–‡æ¡£**: chunk_size=1000, overlap=200
- **ä»£ç æ–‡æ¡£**: chunk_size=1500, overlap=300
- **å­¦æœ¯è®ºæ–‡**: chunk_size=1200, overlap=250
- **å¯¹è¯è®°å½•**: chunk_size=500, overlap=50

### 2. é€‰æ‹©æ£€ç´¢ç­–ç•¥

- **ç›¸ä¼¼åº¦æ£€ç´¢ï¼ˆsimilarityï¼‰**: æœ€å¿«ï¼Œé€‚åˆå¤§å¤šæ•°æƒ…å†µ
- **MMR æ£€ç´¢ï¼ˆmmrï¼‰**: ç»“æœæ›´å¤šæ ·åŒ–ï¼Œé¿å…é‡å¤
- **é˜ˆå€¼è¿‡æ»¤ï¼ˆsimilarity_score_thresholdï¼‰**: åªè¿”å›é«˜è´¨é‡ç»“æœ

### 3. ä¼˜åŒ–æ£€ç´¢å‚æ•°

- `k`: é€šå¸¸è®¾ç½®ä¸º 3-5
- `score_threshold`: 0.5-0.7 ä¹‹é—´
- `fetch_k`: MMR æ¨¡å¼ä¸‹è®¾ç½®ä¸º k çš„ 3-5 å€

### 4. Embedding æ¨¡å‹é€‰æ‹©

- **text-embedding-3-small**: å¿«é€Ÿã€ä¾¿å®œï¼Œé€‚åˆå¼€å‘æµ‹è¯•
- **text-embedding-3-large**: é«˜è´¨é‡ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒ

### 5. ç´¢å¼•ç®¡ç†

- å®šæœŸæ›´æ–°ç´¢å¼•ä»¥åŒ…å«æ–°æ–‡æ¡£
- ä¸ºä¸åŒç±»å‹çš„æ–‡æ¡£åˆ›å»ºç‹¬ç«‹ç´¢å¼•
- ä½¿ç”¨æè¿°æ€§çš„ç´¢å¼•åç§°

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜ 1: æ‰¾ä¸åˆ°æ–‡æ¡£

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥æ–‡æ¡£è·¯å¾„æ˜¯å¦æ­£ç¡®
- ç¡®ä¿æ–‡æ¡£æ ¼å¼å—æ”¯æŒ
- æŸ¥çœ‹æ—¥å¿—äº†è§£è¯¦ç»†é”™è¯¯

### é—®é¢˜ 2: ç´¢å¼•åˆ›å»ºå¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥ OpenAI API Key æ˜¯å¦é…ç½®
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´
- æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å¯è¯»

### é—®é¢˜ 3: æŸ¥è¯¢ç»“æœä¸å‡†ç¡®

**è§£å†³æ–¹æ¡ˆ**:
- è°ƒæ•´ chunk_size å’Œ overlap
- å°è¯•ä¸åŒçš„æ£€ç´¢ç­–ç•¥
- å¢åŠ  k å€¼è·å–æ›´å¤šä¸Šä¸‹æ–‡
- ä½¿ç”¨æ›´å¤§çš„ embedding æ¨¡å‹

### é—®é¢˜ 4: æŸ¥è¯¢é€Ÿåº¦æ…¢

**è§£å†³æ–¹æ¡ˆ**:
- å‡å°‘ k å€¼
- ä½¿ç”¨ FAISS è€Œä¸æ˜¯ InMemory
- è€ƒè™‘ä½¿ç”¨æ›´å°çš„ embedding æ¨¡å‹

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

åŸºäºæµ‹è¯•æ–‡æ¡£ï¼ˆ3 ä¸ªæ–‡ä»¶ï¼Œçº¦ 10,000 å­—ï¼‰ï¼š

- **ç´¢å¼•åˆ›å»ºæ—¶é—´**: ~30 ç§’
- **æŸ¥è¯¢å“åº”æ—¶é—´**: ~2-3 ç§’
- **ç´¢å¼•å¤§å°**: ~5 MB
- **å†…å­˜å ç”¨**: ~200 MB

## ğŸ“ å­¦ä¹ èµ„æº

### LangChain æ–‡æ¡£

- [Retrieval](https://docs.langchain.com/oss/python/langchain/retrieval)
- [Document Loaders](https://reference.langchain.com/python/langchain_core/document_loaders/)
- [Text Splitters](https://reference.langchain.com/python/langchain_text_splitters/)
- [Vector Stores](https://reference.langchain.com/python/langchain_core/vectorstores/)

### ç›¸å…³æ¦‚å¿µ

- RAG åŸç†å’Œåº”ç”¨
- å‘é‡æ•°æ®åº“å¯¹æ¯”
- Embedding æ¨¡å‹é€‰æ‹©
- æ£€ç´¢ä¼˜åŒ–æŠ€å·§

## ğŸ› å·²çŸ¥é—®é¢˜

1. PDF åŠ è½½å¯èƒ½åœ¨æŸäº›æ ¼å¼ä¸Šå¤±è´¥ â†’ ä½¿ç”¨å…¶ä»–æ ¼å¼æˆ–æ‰‹åŠ¨è½¬æ¢
2. å¤§æ–‡ä»¶å¤„ç†å¯èƒ½è¾ƒæ…¢ â†’ è€ƒè™‘åˆ†æ‰¹å¤„ç†
3. æŸäº›ç‰¹æ®Šå­—ç¬¦å¯èƒ½å¯¼è‡´åˆ†å—é—®é¢˜ â†’ é¢„å¤„ç†æ–‡æœ¬

## ğŸ”œ ä¸‹ä¸€æ­¥

å®Œæˆç¬¬ 2 é˜¶æ®µåï¼Œå¯ä»¥ç»§ç»­ï¼š

- **ç¬¬ 3 é˜¶æ®µ**: LangGraph è‡ªå®šä¹‰å·¥ä½œæµ
- **ç¬¬ 4 é˜¶æ®µ**: DeepAgents æ·±åº¦ç ”ç©¶
- **ç¬¬ 5 é˜¶æ®µ**: Guardrails å®‰å…¨è¿‡æ»¤

## ğŸ“ è·å–å¸®åŠ©

é‡åˆ°é—®é¢˜ï¼Ÿ
1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ `logs/app.log`
2. æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®
3. å‚è€ƒç¤ºä¾‹ä»£ç 
4. æŸ¥é˜… LangChain å®˜æ–¹æ–‡æ¡£

